{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psSg2pvghrou"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "uDeCR0k4i75z"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Reading the ETPC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This is the ETPC dataset compiled by Wahle and posted on HuggingFace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "9Zb32aXAjlKl"
      },
      "outputs": [],
      "source": [
        "# Unpickle etpc_raw\n",
        "etpc = pd.read_pickle('datasets/etpc_raw.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "These are the XML files from the ETPC github repo.\n",
        "\n",
        "The first one contains all pairs marked as paraphrases by the MRPC:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "textual_paraphrases = pd.read_xml('datasets/etpc/textual_paraphrases.xml')\n",
        "# Convert scopes from strings to lists of ints\n",
        "textual_paraphrases['s1_scope'] = textual_paraphrases['s1_scope'].apply(lambda x: [int(n) for n in x.split(',')] if type(x) == str else x)\n",
        "textual_paraphrases['s2_scope'] = textual_paraphrases['s2_scope'].apply(lambda x: [int(n) for n in x.split(',')] if type(x) == str else x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The second one contains the text and pair ids for *all* sentence pairs (paraphrases or not). It doesn't contain any data on whether they're paraphrases or not, or what EPT types are in them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "pairs = pd.read_xml('datasets/etpc/text_pairs.xml')\n",
        "pairs.drop(columns=['negation'], inplace=True)\n",
        "pairs.set_index('pair_id', inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7fEbR8ahnyT"
      },
      "source": [
        "# Cleanup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cleaning up Columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>idx</th>\n",
              "      <th>sentence1</th>\n",
              "      <th>sentence2</th>\n",
              "      <th>sentence1_tokenized</th>\n",
              "      <th>sentence2_tokenized</th>\n",
              "      <th>etpc_label</th>\n",
              "      <th>mrpc_label</th>\n",
              "      <th>ept_names</th>\n",
              "      <th>ept_ids</th>\n",
              "      <th>sentence1_segment_location</th>\n",
              "      <th>sentence2_segment_location</th>\n",
              "      <th>sentence1_segment_location_indices</th>\n",
              "      <th>sentence2_segment_location_indices</th>\n",
              "      <th>sentence1_segment_text</th>\n",
              "      <th>sentence2_segment_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1_0</td>\n",
              "      <td>Amrozi accused his brother, whom he called \"th...</td>\n",
              "      <td>Referring to him as only \"the witness\", Amrozi...</td>\n",
              "      <td>[Amrozi, accused, his, brother, ,, whom, he, c...</td>\n",
              "      <td>[Referring, to, him, as, only, ``, the, witnes...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>[Same Polarity Substitution (habitual), Same P...</td>\n",
              "      <td>[5, 6, 26, 25, 29]</td>\n",
              "      <td>[26, 26, 26, 26, 0, 5, 0, 6, 25, 25, 25, 25, 2...</td>\n",
              "      <td>[6, 5, 5, 0, 25, 0, 0, 0, 0, 0, 26, 26, 26, 26...</td>\n",
              "      <td>[[5], [7], [0, 1, 2, 3], [8, 9, 10, 11, 12, 13...</td>\n",
              "      <td>[[1, 2], [0], [10, 11, 12, 13], [4]]</td>\n",
              "      <td>[whom, called, Amrozi accused his brother, `` ...</td>\n",
              "      <td>[to him, Referring, Amrozi accused his brother...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2_1</td>\n",
              "      <td>Yucaipa owned Dominick's before selling the ch...</td>\n",
              "      <td>Yucaipa bought Dominick's in 1995 for $693 mil...</td>\n",
              "      <td>[Yucaipa, owned, Dominick, 's, before, selling...</td>\n",
              "      <td>[Yucaipa, bought, Dominick, 's, in, 1995, for,...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3_2</td>\n",
              "      <td>They had published an advertisement on the Int...</td>\n",
              "      <td>On June 10, the ship's owners had published an...</td>\n",
              "      <td>[They, had, published, an, advertisement, on, ...</td>\n",
              "      <td>[On, June, 10, ,, the, ship, 's, owners, had, ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>[Same Polarity Substitution (contextual), Same...</td>\n",
              "      <td>[6, 6, 26, 25, 29]</td>\n",
              "      <td>[6, 0, 0, 0, 0, 0, 0, 0, 26, 26, 26, 0, 0, 0, ...</td>\n",
              "      <td>[26, 26, 26, 26, 6, 6, 6, 6, 25, 25, 25, 25, 2...</td>\n",
              "      <td>[[0], [14], [8, 9, 10], [17, 18, 19]]</td>\n",
              "      <td>[[4, 5, 6, 7], [18], [0, 1, 2, 3], [8, 9, 10, ...</td>\n",
              "      <td>[They, cargo, on June 10, , he added, had publ...</td>\n",
              "      <td>[the ship 's owners, explosives, On June 10 ,,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4_3</td>\n",
              "      <td>Around 0335 GMT, Tab shares were up 19 cents, ...</td>\n",
              "      <td>Tab shares jumped 20 cents, or 4.6%, to set a ...</td>\n",
              "      <td>[Around, 0335, GMT, ,, Tab, shares, were, up, ...</td>\n",
              "      <td>[Tab, shares, jumped, 20, cents, ,, or, 4.6, %...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5_4</td>\n",
              "      <td>The stock rose $2.11, or about 11 percent, to ...</td>\n",
              "      <td>PG&amp;E Corp. shares jumped $1.63 or 8 percent to...</td>\n",
              "      <td>[The, stock, rose, $, 2.11, ,, or, about, 11, ...</td>\n",
              "      <td>[PG, &amp;, E, Corp., shares, jumped, $, 1.63, or,...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>[Same Polarity Substitution (contextual), Same...</td>\n",
              "      <td>[6, 5, 6, 11, 26, 25, 29, 30, 30, 30, 21]</td>\n",
              "      <td>[6, 6, 5, 29, 30, 0, 29, 25, 30, 29, 0, 6, 6, ...</td>\n",
              "      <td>[30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 3...</td>\n",
              "      <td>[[0, 1], [2], [11, 12, 14], [13], [13], [7], [...</td>\n",
              "      <td>[[0, 1, 2, 3, 4], [5], [11], [20, 21], [20, 21...</td>\n",
              "      <td>[The stock, rose, to close at, Friday, Friday,...</td>\n",
              "      <td>[PG &amp; E Corp. shares, jumped, to, on Friday, o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5796</th>\n",
              "      <td>5797_5796</td>\n",
              "      <td>After Hughes refused to rehire Hernandez, he c...</td>\n",
              "      <td>Hernandez filed an Equal Employment Opportunit...</td>\n",
              "      <td>[After, Hughes, refused, to, rehire, Hernandez...</td>\n",
              "      <td>[Hernandez, filed, an, Equal, Employment, Oppo...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5797</th>\n",
              "      <td>5798_5797</td>\n",
              "      <td>There are 103 Democrats in the Assembly and 47...</td>\n",
              "      <td>Democrats dominate the Assembly while Republic...</td>\n",
              "      <td>[There, are, 103, Democrats, in, the, Assembly...</td>\n",
              "      <td>[Democrats, dominate, the, Assembly, while, Re...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5798</th>\n",
              "      <td>5799_5798</td>\n",
              "      <td>Bethany Hamilton remained in stable condition ...</td>\n",
              "      <td>Bethany, who remained in stable condition afte...</td>\n",
              "      <td>[Bethany, Hamilton, remained, in, stable, cond...</td>\n",
              "      <td>[Bethany, ,, who, remained, in, stable, condit...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5799</th>\n",
              "      <td>5800_5799</td>\n",
              "      <td>Last week the power station’s US owners, AES C...</td>\n",
              "      <td>The news comes after Drax's American owner, AE...</td>\n",
              "      <td>[Last, week, the, power, station’s, US, owners...</td>\n",
              "      <td>[The, news, comes, after, Drax, 's, American, ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>[Spelling changes, Same Polarity Substitution ...</td>\n",
              "      <td>[4, 7, 6, 1, 26, 25, 25, 25, 29]</td>\n",
              "      <td>[26, 26, 0, 7, 7, 6, 1, 25, 25, 4, 25, 25, 25,...</td>\n",
              "      <td>[25, 25, 25, 25, 7, 0, 6, 1, 0, 0, 4, 25, 0, 2...</td>\n",
              "      <td>[[9], [3, 4], [5], [6], [0, 1], [24], [7, 8, 1...</td>\n",
              "      <td>[[10], [4], [6], [7], [13, 14], [0, 1, 2, 3], ...</td>\n",
              "      <td>[Corp, power station’s, US, owners, Last week,...</td>\n",
              "      <td>[Corp., Drax, American, owner, last week, The ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5800</th>\n",
              "      <td>5801_5800</td>\n",
              "      <td>Sobig.F spreads when unsuspecting computer use...</td>\n",
              "      <td>The virus spreads when unsuspecting computer u...</td>\n",
              "      <td>[Sobig.F, spreads, when, unsuspecting, compute...</td>\n",
              "      <td>[The, virus, spreads, when, unsuspecting, comp...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>[Same Polarity Substitution (named ent.), Same...</td>\n",
              "      <td>[7, 6, 6, 11, 25, 29]</td>\n",
              "      <td>[7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 11, 11...</td>\n",
              "      <td>[7, 7, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,...</td>\n",
              "      <td>[[0], [16], [21], [13, 14], [29, 30, 31, 32, 3...</td>\n",
              "      <td>[[0, 1], [16], [22], [14], [2, 3, 4, 5, 6, 7, ...</td>\n",
              "      <td>[Sobig.F, as, ,, such familiar, `` Re : That M...</td>\n",
              "      <td>[The virus, like, and, familiar, spreads when ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5801 rows × 15 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            idx                                          sentence1  \\\n",
              "0           1_0  Amrozi accused his brother, whom he called \"th...   \n",
              "1           2_1  Yucaipa owned Dominick's before selling the ch...   \n",
              "2           3_2  They had published an advertisement on the Int...   \n",
              "3           4_3  Around 0335 GMT, Tab shares were up 19 cents, ...   \n",
              "4           5_4  The stock rose $2.11, or about 11 percent, to ...   \n",
              "...         ...                                                ...   \n",
              "5796  5797_5796  After Hughes refused to rehire Hernandez, he c...   \n",
              "5797  5798_5797  There are 103 Democrats in the Assembly and 47...   \n",
              "5798  5799_5798  Bethany Hamilton remained in stable condition ...   \n",
              "5799  5800_5799  Last week the power station’s US owners, AES C...   \n",
              "5800  5801_5800  Sobig.F spreads when unsuspecting computer use...   \n",
              "\n",
              "                                              sentence2  \\\n",
              "0     Referring to him as only \"the witness\", Amrozi...   \n",
              "1     Yucaipa bought Dominick's in 1995 for $693 mil...   \n",
              "2     On June 10, the ship's owners had published an...   \n",
              "3     Tab shares jumped 20 cents, or 4.6%, to set a ...   \n",
              "4     PG&E Corp. shares jumped $1.63 or 8 percent to...   \n",
              "...                                                 ...   \n",
              "5796  Hernandez filed an Equal Employment Opportunit...   \n",
              "5797  Democrats dominate the Assembly while Republic...   \n",
              "5798  Bethany, who remained in stable condition afte...   \n",
              "5799  The news comes after Drax's American owner, AE...   \n",
              "5800  The virus spreads when unsuspecting computer u...   \n",
              "\n",
              "                                    sentence1_tokenized  \\\n",
              "0     [Amrozi, accused, his, brother, ,, whom, he, c...   \n",
              "1     [Yucaipa, owned, Dominick, 's, before, selling...   \n",
              "2     [They, had, published, an, advertisement, on, ...   \n",
              "3     [Around, 0335, GMT, ,, Tab, shares, were, up, ...   \n",
              "4     [The, stock, rose, $, 2.11, ,, or, about, 11, ...   \n",
              "...                                                 ...   \n",
              "5796  [After, Hughes, refused, to, rehire, Hernandez...   \n",
              "5797  [There, are, 103, Democrats, in, the, Assembly...   \n",
              "5798  [Bethany, Hamilton, remained, in, stable, cond...   \n",
              "5799  [Last, week, the, power, station’s, US, owners...   \n",
              "5800  [Sobig.F, spreads, when, unsuspecting, compute...   \n",
              "\n",
              "                                    sentence2_tokenized  etpc_label  \\\n",
              "0     [Referring, to, him, as, only, ``, the, witnes...           1   \n",
              "1     [Yucaipa, bought, Dominick, 's, in, 1995, for,...           0   \n",
              "2     [On, June, 10, ,, the, ship, 's, owners, had, ...           1   \n",
              "3     [Tab, shares, jumped, 20, cents, ,, or, 4.6, %...           0   \n",
              "4     [PG, &, E, Corp., shares, jumped, $, 1.63, or,...           0   \n",
              "...                                                 ...         ...   \n",
              "5796  [Hernandez, filed, an, Equal, Employment, Oppo...           0   \n",
              "5797  [Democrats, dominate, the, Assembly, while, Re...           0   \n",
              "5798  [Bethany, ,, who, remained, in, stable, condit...           0   \n",
              "5799  [The, news, comes, after, Drax, 's, American, ...           1   \n",
              "5800  [The, virus, spreads, when, unsuspecting, comp...           1   \n",
              "\n",
              "      mrpc_label                                          ept_names  \\\n",
              "0              1  [Same Polarity Substitution (habitual), Same P...   \n",
              "1              0                                                 []   \n",
              "2              1  [Same Polarity Substitution (contextual), Same...   \n",
              "3              0                                                 []   \n",
              "4              1  [Same Polarity Substitution (contextual), Same...   \n",
              "...          ...                                                ...   \n",
              "5796           0                                                 []   \n",
              "5797           0                                                 []   \n",
              "5798           0                                                 []   \n",
              "5799           1  [Spelling changes, Same Polarity Substitution ...   \n",
              "5800           1  [Same Polarity Substitution (named ent.), Same...   \n",
              "\n",
              "                                        ept_ids  \\\n",
              "0                            [5, 6, 26, 25, 29]   \n",
              "1                                            []   \n",
              "2                            [6, 6, 26, 25, 29]   \n",
              "3                                            []   \n",
              "4     [6, 5, 6, 11, 26, 25, 29, 30, 30, 30, 21]   \n",
              "...                                         ...   \n",
              "5796                                         []   \n",
              "5797                                         []   \n",
              "5798                                         []   \n",
              "5799           [4, 7, 6, 1, 26, 25, 25, 25, 29]   \n",
              "5800                      [7, 6, 6, 11, 25, 29]   \n",
              "\n",
              "                             sentence1_segment_location  \\\n",
              "0     [26, 26, 26, 26, 0, 5, 0, 6, 25, 25, 25, 25, 2...   \n",
              "1     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "2     [6, 0, 0, 0, 0, 0, 0, 0, 26, 26, 26, 0, 0, 0, ...   \n",
              "3     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "4     [6, 6, 5, 29, 30, 0, 29, 25, 30, 29, 0, 6, 6, ...   \n",
              "...                                                 ...   \n",
              "5796   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
              "5797                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
              "5798            [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
              "5799  [26, 26, 0, 7, 7, 6, 1, 25, 25, 4, 25, 25, 25,...   \n",
              "5800  [7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 11, 11...   \n",
              "\n",
              "                             sentence2_segment_location  \\\n",
              "0     [6, 5, 5, 0, 25, 0, 0, 0, 0, 0, 26, 26, 26, 26...   \n",
              "1     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "2     [26, 26, 26, 26, 6, 6, 6, 6, 25, 25, 25, 25, 2...   \n",
              "3     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "4     [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 3...   \n",
              "...                                                 ...   \n",
              "5796                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
              "5797                     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]   \n",
              "5798  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "5799  [25, 25, 25, 25, 7, 0, 6, 1, 0, 0, 4, 25, 0, 2...   \n",
              "5800  [7, 7, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,...   \n",
              "\n",
              "                     sentence1_segment_location_indices  \\\n",
              "0     [[5], [7], [0, 1, 2, 3], [8, 9, 10, 11, 12, 13...   \n",
              "1                                                    []   \n",
              "2                 [[0], [14], [8, 9, 10], [17, 18, 19]]   \n",
              "3                                                    []   \n",
              "4     [[0, 1], [2], [11, 12, 14], [13], [13], [7], [...   \n",
              "...                                                 ...   \n",
              "5796                                                 []   \n",
              "5797                                                 []   \n",
              "5798                                                 []   \n",
              "5799  [[9], [3, 4], [5], [6], [0, 1], [24], [7, 8, 1...   \n",
              "5800  [[0], [16], [21], [13, 14], [29, 30, 31, 32, 3...   \n",
              "\n",
              "                     sentence2_segment_location_indices  \\\n",
              "0                  [[1, 2], [0], [10, 11, 12, 13], [4]]   \n",
              "1                                                    []   \n",
              "2     [[4, 5, 6, 7], [18], [0, 1, 2, 3], [8, 9, 10, ...   \n",
              "3                                                    []   \n",
              "4     [[0, 1, 2, 3, 4], [5], [11], [20, 21], [20, 21...   \n",
              "...                                                 ...   \n",
              "5796                                                 []   \n",
              "5797                                                 []   \n",
              "5798                                                 []   \n",
              "5799  [[10], [4], [6], [7], [13, 14], [0, 1, 2, 3], ...   \n",
              "5800  [[0, 1], [16], [22], [14], [2, 3, 4, 5, 6, 7, ...   \n",
              "\n",
              "                                 sentence1_segment_text  \\\n",
              "0     [whom, called, Amrozi accused his brother, `` ...   \n",
              "1                                                    []   \n",
              "2     [They, cargo, on June 10, , he added, had publ...   \n",
              "3                                                    []   \n",
              "4     [The stock, rose, to close at, Friday, Friday,...   \n",
              "...                                                 ...   \n",
              "5796                                                 []   \n",
              "5797                                                 []   \n",
              "5798                                                 []   \n",
              "5799  [Corp, power station’s, US, owners, Last week,...   \n",
              "5800  [Sobig.F, as, ,, such familiar, `` Re : That M...   \n",
              "\n",
              "                                 sentence2_segment_text  \n",
              "0     [to him, Referring, Amrozi accused his brother...  \n",
              "1                                                    []  \n",
              "2     [the ship 's owners, explosives, On June 10 ,,...  \n",
              "3                                                    []  \n",
              "4     [PG & E Corp. shares, jumped, to, on Friday, o...  \n",
              "...                                                 ...  \n",
              "5796                                                 []  \n",
              "5797                                                 []  \n",
              "5798                                                 []  \n",
              "5799  [Corp., Drax, American, owner, last week, The ...  \n",
              "5800  [The virus, like, and, familiar, spreads when ...  \n",
              "\n",
              "[5801 rows x 15 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "etpc.rename(columns={'paraphrase_type_ids': 'ept_ids', 'paraphrase_types': 'ept_names'}, inplace=True)\n",
        "etpc.drop(columns={'negation'}, axis=1, inplace=True)\n",
        "etpc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4V4ebL-5iVhu"
      },
      "source": [
        "# Remapping paraphrase IDs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1r_HM5DuiwbU"
      },
      "source": [
        "First, make a list with paraphrase types and IDs from the ETPC:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 896
        },
        "id": "g-NHZrIEj_uW",
        "outputId": "c9d1ecfb-59ed-4a96-fd6f-0fc6be15090e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ept_id</th>\n",
              "      <th>ept_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Inflectional Changes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Modal Verb Changes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Derivational Changes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Spelling changes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Same Polarity Substitution (habitual)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>Same Polarity Substitution (contextual)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>Same Polarity Substitution (named ent.)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>Change of format</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>Opposite polarity substitution (habitual)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>Opposite polarity substitution (contextual)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>11</td>\n",
              "      <td>Synthetic/analytic substitution</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>13</td>\n",
              "      <td>Converse substitution</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>14</td>\n",
              "      <td>Diathesis alternation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>15</td>\n",
              "      <td>Negation switching</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>16</td>\n",
              "      <td>Ellipsis</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>17</td>\n",
              "      <td>Coordination changes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>18</td>\n",
              "      <td>Subordination and nesting changes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>21</td>\n",
              "      <td>Punctuation changes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>22</td>\n",
              "      <td>Direct/indirect style alternations</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>23</td>\n",
              "      <td>Sentence modality changes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>24</td>\n",
              "      <td>Syntax/discourse structure changes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>25</td>\n",
              "      <td>Addition/Deletion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>26</td>\n",
              "      <td>Change of order</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>28</td>\n",
              "      <td>Semantic based</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>29</td>\n",
              "      <td>Identity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>30</td>\n",
              "      <td>Non-paraphrase</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>31</td>\n",
              "      <td>Entailment</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    ept_id                                     ept_name\n",
              "0        1                         Inflectional Changes\n",
              "1        2                           Modal Verb Changes\n",
              "2        3                         Derivational Changes\n",
              "3        4                             Spelling changes\n",
              "4        5        Same Polarity Substitution (habitual)\n",
              "5        6      Same Polarity Substitution (contextual)\n",
              "6        7      Same Polarity Substitution (named ent.)\n",
              "7        8                             Change of format\n",
              "8        9    Opposite polarity substitution (habitual)\n",
              "9       10  Opposite polarity substitution (contextual)\n",
              "10      11              Synthetic/analytic substitution\n",
              "11      13                        Converse substitution\n",
              "12      14                        Diathesis alternation\n",
              "13      15                           Negation switching\n",
              "14      16                                     Ellipsis\n",
              "15      17                         Coordination changes\n",
              "16      18            Subordination and nesting changes\n",
              "17      21                          Punctuation changes\n",
              "18      22           Direct/indirect style alternations\n",
              "19      23                    Sentence modality changes\n",
              "20      24           Syntax/discourse structure changes\n",
              "21      25                            Addition/Deletion\n",
              "22      26                              Change of order\n",
              "23      28                               Semantic based\n",
              "24      29                                     Identity\n",
              "25      30                               Non-paraphrase\n",
              "26      31                                   Entailment"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "id_map = pd.read_xml('https://raw.githubusercontent.com/venelink/ETPC/master/Corpus/paraphrase_types.xml')\n",
        "# Rename columns for clarity\n",
        "id_map.rename(columns={'type_id': 'ept_id', 'type_name': 'ept_name'}, inplace=True)\n",
        "# Drop unused data\n",
        "id_map = id_map[['ept_id', 'ept_name']] # No use for type_category column\n",
        "id_map.drop(id_map.tail(2).index,inplace=True) # Types don't appear in ETPC\n",
        "id_map.style.hide(axis=\"index\")\n",
        "id_map"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igg_sqcRliXX"
      },
      "source": [
        "Now, make a list with paraphrase names and IDs for ParaOp types"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "ONILD3V0lucp",
        "outputId": "38f25e64-a353-47bb-81b3-fbfa8c09302a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>paraop_name</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>paraop_id</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>No change</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Addition/Deletion - Function Word</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Addition/Deletion - Content Word</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Change of Order</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Substitution - Synonym</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Substitution - Contextual Synonym</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Substitution - Morphological</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Substitution - Spelling and Format</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  paraop_name\n",
              "paraop_id                                    \n",
              "0                                   No change\n",
              "1           Addition/Deletion - Function Word\n",
              "2            Addition/Deletion - Content Word\n",
              "3                             Change of Order\n",
              "4                      Substitution - Synonym\n",
              "5           Substitution - Contextual Synonym\n",
              "6                Substitution - Morphological\n",
              "7          Substitution - Spelling and Format"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = [[0, 'No change'],\n",
        "        [1, 'Addition/Deletion - Function Word'],\n",
        "        [2, 'Addition/Deletion - Content Word'],\n",
        "        [3, 'Change of Order'],\n",
        "        [4, 'Substitution - Synonym'],\n",
        "        [5, 'Substitution - Contextual Synonym'],\n",
        "        [6, 'Substitution - Morphological'],\n",
        "        [7, 'Substitution - Spelling and Format']\n",
        "       ]\n",
        "paraop_map = pd.DataFrame(data, columns = ['paraop_id', 'paraop_name'])\n",
        "paraop_map.set_index('paraop_id', inplace=True)\n",
        "paraop_map"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Mapping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We'll use the dataframe below for mapping. Each row will contain the name and ID of a paraphrase type in the ETPC, and the name and ID of the correspondent ParaOp type."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 896
        },
        "id": "_jwKfRbRizo0",
        "outputId": "b0a0994c-22c8-4197-907d-f10095b5d1e4"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ept_id</th>\n",
              "      <th>ept_name</th>\n",
              "      <th>paraop_id</th>\n",
              "      <th>paraop_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Inflectional Changes</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Modal Verb Changes</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Derivational Changes</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Spelling changes</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Same Polarity Substitution (habitual)</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>Same Polarity Substitution (contextual)</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>Same Polarity Substitution (named ent.)</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>Change of format</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>Opposite polarity substitution (habitual)</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>Opposite polarity substitution (contextual)</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>11</td>\n",
              "      <td>Synthetic/analytic substitution</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>13</td>\n",
              "      <td>Converse substitution</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>14</td>\n",
              "      <td>Diathesis alternation</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>15</td>\n",
              "      <td>Negation switching</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>16</td>\n",
              "      <td>Ellipsis</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>17</td>\n",
              "      <td>Coordination changes</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>18</td>\n",
              "      <td>Subordination and nesting changes</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>21</td>\n",
              "      <td>Punctuation changes</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>22</td>\n",
              "      <td>Direct/indirect style alternations</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>23</td>\n",
              "      <td>Sentence modality changes</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>24</td>\n",
              "      <td>Syntax/discourse structure changes</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>25</td>\n",
              "      <td>Addition/Deletion</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>26</td>\n",
              "      <td>Change of order</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>28</td>\n",
              "      <td>Semantic based</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>29</td>\n",
              "      <td>Identity</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>30</td>\n",
              "      <td>Non-paraphrase</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>31</td>\n",
              "      <td>Entailment</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    ept_id                                     ept_name paraop_id paraop_name\n",
              "0        1                         Inflectional Changes                      \n",
              "1        2                           Modal Verb Changes                      \n",
              "2        3                         Derivational Changes                      \n",
              "3        4                             Spelling changes                      \n",
              "4        5        Same Polarity Substitution (habitual)                      \n",
              "5        6      Same Polarity Substitution (contextual)                      \n",
              "6        7      Same Polarity Substitution (named ent.)                      \n",
              "7        8                             Change of format                      \n",
              "8        9    Opposite polarity substitution (habitual)                      \n",
              "9       10  Opposite polarity substitution (contextual)                      \n",
              "10      11              Synthetic/analytic substitution                      \n",
              "11      13                        Converse substitution                      \n",
              "12      14                        Diathesis alternation                      \n",
              "13      15                           Negation switching                      \n",
              "14      16                                     Ellipsis                      \n",
              "15      17                         Coordination changes                      \n",
              "16      18            Subordination and nesting changes                      \n",
              "17      21                          Punctuation changes                      \n",
              "18      22           Direct/indirect style alternations                      \n",
              "19      23                    Sentence modality changes                      \n",
              "20      24           Syntax/discourse structure changes                      \n",
              "21      25                            Addition/Deletion                      \n",
              "22      26                              Change of order                      \n",
              "23      28                               Semantic based                      \n",
              "24      29                                     Identity                      \n",
              "25      30                               Non-paraphrase                      \n",
              "26      31                                   Entailment                      "
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "id_map['paraop_id'] = ''\n",
        "id_map['paraop_name'] = ''\n",
        "id_map"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUz653FebizJ"
      },
      "source": [
        "Here's where we do the mapping:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "NKrHh2trtJhn"
      },
      "outputs": [],
      "source": [
        "# Helper function to map an ETPC id to a Paraop id\n",
        "def map_id(ept_id, paraop_id):\n",
        "    \"\"\"Given an EPT id and a Paraop id, look up the name of the Paraop id and \n",
        "    fill in the rows of id_map with paraop_id and the name.\"\"\"\n",
        "    id_map.loc[id_map['ept_id'] == ept_id, 'paraop_id'] = paraop_id\n",
        "    id_map.loc[id_map['ept_id'] == ept_id, 'paraop_name'] = paraop_map.loc[paraop_id, 'paraop_name']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 896
        },
        "id": "cbJDHI9LvQ0e",
        "outputId": "dfc86b17-2cdd-47b4-9285-3dbf06772ad2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ept_id</th>\n",
              "      <th>ept_name</th>\n",
              "      <th>paraop_id</th>\n",
              "      <th>paraop_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Inflectional Changes</td>\n",
              "      <td>6</td>\n",
              "      <td>Substitution - Morphological</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Modal Verb Changes</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Derivational Changes</td>\n",
              "      <td>6</td>\n",
              "      <td>Substitution - Morphological</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Spelling changes</td>\n",
              "      <td>7</td>\n",
              "      <td>Substitution - Spelling and Format</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Same Polarity Substitution (habitual)</td>\n",
              "      <td>4</td>\n",
              "      <td>Substitution - Synonym</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>Same Polarity Substitution (contextual)</td>\n",
              "      <td>5</td>\n",
              "      <td>Substitution - Contextual Synonym</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>Same Polarity Substitution (named ent.)</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>Change of format</td>\n",
              "      <td>7</td>\n",
              "      <td>Substitution - Spelling and Format</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>Opposite polarity substitution (habitual)</td>\n",
              "      <td>4</td>\n",
              "      <td>Substitution - Synonym</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>Opposite polarity substitution (contextual)</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>11</td>\n",
              "      <td>Synthetic/analytic substitution</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>13</td>\n",
              "      <td>Converse substitution</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>14</td>\n",
              "      <td>Diathesis alternation</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>15</td>\n",
              "      <td>Negation switching</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>16</td>\n",
              "      <td>Ellipsis</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>17</td>\n",
              "      <td>Coordination changes</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>18</td>\n",
              "      <td>Subordination and nesting changes</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>21</td>\n",
              "      <td>Punctuation changes</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>22</td>\n",
              "      <td>Direct/indirect style alternations</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>23</td>\n",
              "      <td>Sentence modality changes</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>24</td>\n",
              "      <td>Syntax/discourse structure changes</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>25</td>\n",
              "      <td>Addition/Deletion</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>26</td>\n",
              "      <td>Change of order</td>\n",
              "      <td>3</td>\n",
              "      <td>Change of Order</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>28</td>\n",
              "      <td>Semantic based</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>29</td>\n",
              "      <td>Identity</td>\n",
              "      <td>0</td>\n",
              "      <td>No change</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>30</td>\n",
              "      <td>Non-paraphrase</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>31</td>\n",
              "      <td>Entailment</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    ept_id                                     ept_name paraop_id  \\\n",
              "0        1                         Inflectional Changes         6   \n",
              "1        2                           Modal Verb Changes             \n",
              "2        3                         Derivational Changes         6   \n",
              "3        4                             Spelling changes         7   \n",
              "4        5        Same Polarity Substitution (habitual)         4   \n",
              "5        6      Same Polarity Substitution (contextual)         5   \n",
              "6        7      Same Polarity Substitution (named ent.)             \n",
              "7        8                             Change of format         7   \n",
              "8        9    Opposite polarity substitution (habitual)         4   \n",
              "9       10  Opposite polarity substitution (contextual)             \n",
              "10      11              Synthetic/analytic substitution             \n",
              "11      13                        Converse substitution             \n",
              "12      14                        Diathesis alternation             \n",
              "13      15                           Negation switching             \n",
              "14      16                                     Ellipsis             \n",
              "15      17                         Coordination changes             \n",
              "16      18            Subordination and nesting changes             \n",
              "17      21                          Punctuation changes             \n",
              "18      22           Direct/indirect style alternations             \n",
              "19      23                    Sentence modality changes             \n",
              "20      24           Syntax/discourse structure changes             \n",
              "21      25                            Addition/Deletion             \n",
              "22      26                              Change of order         3   \n",
              "23      28                               Semantic based             \n",
              "24      29                                     Identity         0   \n",
              "25      30                               Non-paraphrase             \n",
              "26      31                                   Entailment             \n",
              "\n",
              "                           paraop_name  \n",
              "0         Substitution - Morphological  \n",
              "1                                       \n",
              "2         Substitution - Morphological  \n",
              "3   Substitution - Spelling and Format  \n",
              "4               Substitution - Synonym  \n",
              "5    Substitution - Contextual Synonym  \n",
              "6                                       \n",
              "7   Substitution - Spelling and Format  \n",
              "8               Substitution - Synonym  \n",
              "9                                       \n",
              "10                                      \n",
              "11                                      \n",
              "12                                      \n",
              "13                                      \n",
              "14                                      \n",
              "15                                      \n",
              "16                                      \n",
              "17                                      \n",
              "18                                      \n",
              "19                                      \n",
              "20                                      \n",
              "21                                      \n",
              "22                     Change of Order  \n",
              "23                                      \n",
              "24                           No change  \n",
              "25                                      \n",
              "26                                      "
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "map_id(ept_id=1, paraop_id=6)\n",
        "map_id(ept_id=3, paraop_id=6)\n",
        "map_id(ept_id=26, paraop_id=3)\n",
        "map_id(ept_id=29, paraop_id=0)\n",
        "map_id(4, 7)\n",
        "map_id(5, 4)\n",
        "map_id(6, 5)\n",
        "map_id(8, 7)\n",
        "map_id(9, 4)\n",
        "id_map"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXh7ydJQznCV"
      },
      "source": [
        "TODO: Figure out a way to hide index of map_id throughout whole notebook. For some reason this seems harder than it needs to be..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Helper function to convert an ETPC ID to a Paraop ID"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Helper function to get a Paraop id from an ETPC id\n",
        "def ept_to_paraop(ept_id):\n",
        "    return id_map.loc[id_map['ept_id'] == ept_id, 'paraop_id'].iloc[0]\n",
        "\n",
        "ept_to_paraop(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Reannotation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Creating positives dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_34451/1590217566.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  positives.rename(columns={'sentence1_segment_location': 'sentence1_scope_etpc',\n",
            "/tmp/ipykernel_34451/1590217566.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  positives.drop(columns=['sentence1_segment_location_indices', 'sentence2_segment_location_indices'],inplace=True)\n",
            "/tmp/ipykernel_34451/1590217566.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  positives['idx'] = positives.index.to_series()\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>idx</th>\n",
              "      <th>sentence1</th>\n",
              "      <th>sentence2</th>\n",
              "      <th>sentence1_tokenized</th>\n",
              "      <th>sentence2_tokenized</th>\n",
              "      <th>etpc_label</th>\n",
              "      <th>mrpc_label</th>\n",
              "      <th>ept_names</th>\n",
              "      <th>ept_ids</th>\n",
              "      <th>sentence1_scope_etpc</th>\n",
              "      <th>sentence2_scope_etpc</th>\n",
              "      <th>sentence1_segment_text</th>\n",
              "      <th>sentence2_segment_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Amrozi accused his brother, whom he called \"th...</td>\n",
              "      <td>Referring to him as only \"the witness\", Amrozi...</td>\n",
              "      <td>[Amrozi, accused, his, brother, ,, whom, he, c...</td>\n",
              "      <td>[Referring, to, him, as, only, ``, the, witnes...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>[Same Polarity Substitution (habitual), Same P...</td>\n",
              "      <td>[5, 6, 26, 25, 29]</td>\n",
              "      <td>[26, 26, 26, 26, 0, 5, 0, 6, 25, 25, 25, 25, 2...</td>\n",
              "      <td>[6, 5, 5, 0, 25, 0, 0, 0, 0, 0, 26, 26, 26, 26...</td>\n",
              "      <td>[whom, called, Amrozi accused his brother, `` ...</td>\n",
              "      <td>[to him, Referring, Amrozi accused his brother...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>They had published an advertisement on the Int...</td>\n",
              "      <td>On June 10, the ship's owners had published an...</td>\n",
              "      <td>[They, had, published, an, advertisement, on, ...</td>\n",
              "      <td>[On, June, 10, ,, the, ship, 's, owners, had, ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>[Same Polarity Substitution (contextual), Same...</td>\n",
              "      <td>[6, 6, 26, 25, 29]</td>\n",
              "      <td>[6, 0, 0, 0, 0, 0, 0, 0, 26, 26, 26, 0, 0, 0, ...</td>\n",
              "      <td>[26, 26, 26, 26, 6, 6, 6, 6, 25, 25, 25, 25, 2...</td>\n",
              "      <td>[They, cargo, on June 10, , he added, had publ...</td>\n",
              "      <td>[the ship 's owners, explosives, On June 10 ,,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>The stock rose $2.11, or about 11 percent, to ...</td>\n",
              "      <td>PG&amp;E Corp. shares jumped $1.63 or 8 percent to...</td>\n",
              "      <td>[The, stock, rose, $, 2.11, ,, or, about, 11, ...</td>\n",
              "      <td>[PG, &amp;, E, Corp., shares, jumped, $, 1.63, or,...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>[Same Polarity Substitution (contextual), Same...</td>\n",
              "      <td>[6, 5, 6, 11, 26, 25, 29, 30, 30, 30, 21]</td>\n",
              "      <td>[6, 6, 5, 29, 30, 0, 29, 25, 30, 29, 0, 6, 6, ...</td>\n",
              "      <td>[30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 3...</td>\n",
              "      <td>[The stock, rose, to close at, Friday, Friday,...</td>\n",
              "      <td>[PG &amp; E Corp. shares, jumped, to, on Friday, o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>Revenue in the first quarter of the year dropp...</td>\n",
              "      <td>With the scandal hanging over Stewart's compan...</td>\n",
              "      <td>[Revenue, in, the, first, quarter, of, the, ye...</td>\n",
              "      <td>[With, the, scandal, hanging, over, Stewart, '...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>[Synthetic/analytic substitution, Addition/Del...</td>\n",
              "      <td>[11, 25, 29]</td>\n",
              "      <td>[25, 11, 11, 11, 11, 11, 11, 11, 25, 25, 25, 2...</td>\n",
              "      <td>[25, 25, 25, 25, 25, 25, 25, 25, 25, 0, 11, 11...</td>\n",
              "      <td>[in the first quarter of the year, Revenue dro...</td>\n",
              "      <td>[the first quarter of the year, With the scand...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>The DVD-CCA then appealed to the state Supreme...</td>\n",
              "      <td>The DVD CCA appealed that decision to the U.S....</td>\n",
              "      <td>[The, DVD-CCA, then, appealed, to, the, state,...</td>\n",
              "      <td>[The, DVD, CCA, appealed, that, decision, to, ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>[Spelling changes, Same Polarity Substitution ...</td>\n",
              "      <td>[4, 5, 25, 25, 29]</td>\n",
              "      <td>[25, 4, 25, 25, 25, 25, 5, 25, 25, 25]</td>\n",
              "      <td>[25, 4, 4, 25, 25, 25, 25, 25, 5, 25, 25, 25]</td>\n",
              "      <td>[DVD-CCA, state, then, The appealed to the Sup...</td>\n",
              "      <td>[DVD CCA, U.S., that decision, The appealed to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5792</th>\n",
              "      <td>5792</td>\n",
              "      <td>Gehring waived extradition Monday during a hea...</td>\n",
              "      <td>Gehring waived extradition Monday during a hea...</td>\n",
              "      <td>[Gehring, waived, extradition, Monday, during,...</td>\n",
              "      <td>[Gehring, waived, extradition, Monday, during,...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>[Addition/Deletion, Identity, Punctuation chan...</td>\n",
              "      <td>[25, 29, 21, 6, 11, 14, 26, 25]</td>\n",
              "      <td>[21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 2...</td>\n",
              "      <td>[29, 29, 29, 29, 29, 29, 29, 26, 26, 26, 26, 2...</td>\n",
              "      <td>[authorities said, Gehring waived extradition ...</td>\n",
              "      <td>[Gehring waived extradition Monday during a he...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5793</th>\n",
              "      <td>5793</td>\n",
              "      <td>\"I am advised that certain allegations of crim...</td>\n",
              "      <td>\"I am advised that certain allegations of crim...</td>\n",
              "      <td>[``, I, am, advised, that, certain, allegation...</td>\n",
              "      <td>[``, I, am, advised, that, certain, allegation...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>[Same Polarity Substitution (contextual), Chan...</td>\n",
              "      <td>[6, 26, 25, 29, 21]</td>\n",
              "      <td>[29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 2...</td>\n",
              "      <td>[29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 2...</td>\n",
              "      <td>[Silver, Silver, `` I am advised that certain ...</td>\n",
              "      <td>[the Silver statement, the Silver statement, ,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5795</th>\n",
              "      <td>5795</td>\n",
              "      <td>The deal, approved by both companies' board of...</td>\n",
              "      <td>The acquisition has been approved by both comp...</td>\n",
              "      <td>[The, deal, ,, approved, by, both, companies, ...</td>\n",
              "      <td>[The, acquisition, has, been, approved, by, bo...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>[Same Polarity Substitution (habitual), Same P...</td>\n",
              "      <td>[5, 5, 18, 29, 30]</td>\n",
              "      <td>[29, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 1...</td>\n",
              "      <td>[29, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 1...</td>\n",
              "      <td>[deal, be completed, The deal , approved by bo...</td>\n",
              "      <td>[acquisition, close, The acquisition has been ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5799</th>\n",
              "      <td>5799</td>\n",
              "      <td>Last week the power station’s US owners, AES C...</td>\n",
              "      <td>The news comes after Drax's American owner, AE...</td>\n",
              "      <td>[Last, week, the, power, station’s, US, owners...</td>\n",
              "      <td>[The, news, comes, after, Drax, 's, American, ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>[Spelling changes, Same Polarity Substitution ...</td>\n",
              "      <td>[4, 7, 6, 1, 26, 25, 25, 25, 29]</td>\n",
              "      <td>[26, 26, 0, 7, 7, 6, 1, 25, 25, 4, 25, 25, 25,...</td>\n",
              "      <td>[25, 25, 25, 25, 7, 0, 6, 1, 0, 0, 4, 25, 0, 2...</td>\n",
              "      <td>[Corp, power station’s, US, owners, Last week,...</td>\n",
              "      <td>[Corp., Drax, American, owner, last week, The ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5800</th>\n",
              "      <td>5800</td>\n",
              "      <td>Sobig.F spreads when unsuspecting computer use...</td>\n",
              "      <td>The virus spreads when unsuspecting computer u...</td>\n",
              "      <td>[Sobig.F, spreads, when, unsuspecting, compute...</td>\n",
              "      <td>[The, virus, spreads, when, unsuspecting, comp...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>[Same Polarity Substitution (named ent.), Same...</td>\n",
              "      <td>[7, 6, 6, 11, 25, 29]</td>\n",
              "      <td>[7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 11, 11...</td>\n",
              "      <td>[7, 7, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,...</td>\n",
              "      <td>[Sobig.F, as, ,, such familiar, `` Re : That M...</td>\n",
              "      <td>[The virus, like, and, familiar, spreads when ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3900 rows × 13 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       idx                                          sentence1  \\\n",
              "0        0  Amrozi accused his brother, whom he called \"th...   \n",
              "2        2  They had published an advertisement on the Int...   \n",
              "4        4  The stock rose $2.11, or about 11 percent, to ...   \n",
              "5        5  Revenue in the first quarter of the year dropp...   \n",
              "7        7  The DVD-CCA then appealed to the state Supreme...   \n",
              "...    ...                                                ...   \n",
              "5792  5792  Gehring waived extradition Monday during a hea...   \n",
              "5793  5793  \"I am advised that certain allegations of crim...   \n",
              "5795  5795  The deal, approved by both companies' board of...   \n",
              "5799  5799  Last week the power station’s US owners, AES C...   \n",
              "5800  5800  Sobig.F spreads when unsuspecting computer use...   \n",
              "\n",
              "                                              sentence2  \\\n",
              "0     Referring to him as only \"the witness\", Amrozi...   \n",
              "2     On June 10, the ship's owners had published an...   \n",
              "4     PG&E Corp. shares jumped $1.63 or 8 percent to...   \n",
              "5     With the scandal hanging over Stewart's compan...   \n",
              "7     The DVD CCA appealed that decision to the U.S....   \n",
              "...                                                 ...   \n",
              "5792  Gehring waived extradition Monday during a hea...   \n",
              "5793  \"I am advised that certain allegations of crim...   \n",
              "5795  The acquisition has been approved by both comp...   \n",
              "5799  The news comes after Drax's American owner, AE...   \n",
              "5800  The virus spreads when unsuspecting computer u...   \n",
              "\n",
              "                                    sentence1_tokenized  \\\n",
              "0     [Amrozi, accused, his, brother, ,, whom, he, c...   \n",
              "2     [They, had, published, an, advertisement, on, ...   \n",
              "4     [The, stock, rose, $, 2.11, ,, or, about, 11, ...   \n",
              "5     [Revenue, in, the, first, quarter, of, the, ye...   \n",
              "7     [The, DVD-CCA, then, appealed, to, the, state,...   \n",
              "...                                                 ...   \n",
              "5792  [Gehring, waived, extradition, Monday, during,...   \n",
              "5793  [``, I, am, advised, that, certain, allegation...   \n",
              "5795  [The, deal, ,, approved, by, both, companies, ...   \n",
              "5799  [Last, week, the, power, station’s, US, owners...   \n",
              "5800  [Sobig.F, spreads, when, unsuspecting, compute...   \n",
              "\n",
              "                                    sentence2_tokenized  etpc_label  \\\n",
              "0     [Referring, to, him, as, only, ``, the, witnes...           1   \n",
              "2     [On, June, 10, ,, the, ship, 's, owners, had, ...           1   \n",
              "4     [PG, &, E, Corp., shares, jumped, $, 1.63, or,...           0   \n",
              "5     [With, the, scandal, hanging, over, Stewart, '...           1   \n",
              "7     [The, DVD, CCA, appealed, that, decision, to, ...           1   \n",
              "...                                                 ...         ...   \n",
              "5792  [Gehring, waived, extradition, Monday, during,...           1   \n",
              "5793  [``, I, am, advised, that, certain, allegation...           1   \n",
              "5795  [The, acquisition, has, been, approved, by, bo...           0   \n",
              "5799  [The, news, comes, after, Drax, 's, American, ...           1   \n",
              "5800  [The, virus, spreads, when, unsuspecting, comp...           1   \n",
              "\n",
              "      mrpc_label                                          ept_names  \\\n",
              "0              1  [Same Polarity Substitution (habitual), Same P...   \n",
              "2              1  [Same Polarity Substitution (contextual), Same...   \n",
              "4              1  [Same Polarity Substitution (contextual), Same...   \n",
              "5              1  [Synthetic/analytic substitution, Addition/Del...   \n",
              "7              1  [Spelling changes, Same Polarity Substitution ...   \n",
              "...          ...                                                ...   \n",
              "5792           1  [Addition/Deletion, Identity, Punctuation chan...   \n",
              "5793           1  [Same Polarity Substitution (contextual), Chan...   \n",
              "5795           1  [Same Polarity Substitution (habitual), Same P...   \n",
              "5799           1  [Spelling changes, Same Polarity Substitution ...   \n",
              "5800           1  [Same Polarity Substitution (named ent.), Same...   \n",
              "\n",
              "                                        ept_ids  \\\n",
              "0                            [5, 6, 26, 25, 29]   \n",
              "2                            [6, 6, 26, 25, 29]   \n",
              "4     [6, 5, 6, 11, 26, 25, 29, 30, 30, 30, 21]   \n",
              "5                                  [11, 25, 29]   \n",
              "7                            [4, 5, 25, 25, 29]   \n",
              "...                                         ...   \n",
              "5792            [25, 29, 21, 6, 11, 14, 26, 25]   \n",
              "5793                        [6, 26, 25, 29, 21]   \n",
              "5795                         [5, 5, 18, 29, 30]   \n",
              "5799           [4, 7, 6, 1, 26, 25, 25, 25, 29]   \n",
              "5800                      [7, 6, 6, 11, 25, 29]   \n",
              "\n",
              "                                   sentence1_scope_etpc  \\\n",
              "0     [26, 26, 26, 26, 0, 5, 0, 6, 25, 25, 25, 25, 2...   \n",
              "2     [6, 0, 0, 0, 0, 0, 0, 0, 26, 26, 26, 0, 0, 0, ...   \n",
              "4     [6, 6, 5, 29, 30, 0, 29, 25, 30, 29, 0, 6, 6, ...   \n",
              "5     [25, 11, 11, 11, 11, 11, 11, 11, 25, 25, 25, 2...   \n",
              "7                [25, 4, 25, 25, 25, 25, 5, 25, 25, 25]   \n",
              "...                                                 ...   \n",
              "5792  [21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 2...   \n",
              "5793  [29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 2...   \n",
              "5795  [29, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 1...   \n",
              "5799  [26, 26, 0, 7, 7, 6, 1, 25, 25, 4, 25, 25, 25,...   \n",
              "5800  [7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 11, 11...   \n",
              "\n",
              "                                   sentence2_scope_etpc  \\\n",
              "0     [6, 5, 5, 0, 25, 0, 0, 0, 0, 0, 26, 26, 26, 26...   \n",
              "2     [26, 26, 26, 26, 6, 6, 6, 6, 25, 25, 25, 25, 2...   \n",
              "4     [30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 30, 3...   \n",
              "5     [25, 25, 25, 25, 25, 25, 25, 25, 25, 0, 11, 11...   \n",
              "7         [25, 4, 4, 25, 25, 25, 25, 25, 5, 25, 25, 25]   \n",
              "...                                                 ...   \n",
              "5792  [29, 29, 29, 29, 29, 29, 29, 26, 26, 26, 26, 2...   \n",
              "5793  [29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 2...   \n",
              "5795  [29, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 1...   \n",
              "5799  [25, 25, 25, 25, 7, 0, 6, 1, 0, 0, 4, 25, 0, 2...   \n",
              "5800  [7, 7, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,...   \n",
              "\n",
              "                                 sentence1_segment_text  \\\n",
              "0     [whom, called, Amrozi accused his brother, `` ...   \n",
              "2     [They, cargo, on June 10, , he added, had publ...   \n",
              "4     [The stock, rose, to close at, Friday, Friday,...   \n",
              "5     [in the first quarter of the year, Revenue dro...   \n",
              "7     [DVD-CCA, state, then, The appealed to the Sup...   \n",
              "...                                                 ...   \n",
              "5792  [authorities said, Gehring waived extradition ...   \n",
              "5793  [Silver, Silver, `` I am advised that certain ...   \n",
              "5795  [deal, be completed, The deal , approved by bo...   \n",
              "5799  [Corp, power station’s, US, owners, Last week,...   \n",
              "5800  [Sobig.F, as, ,, such familiar, `` Re : That M...   \n",
              "\n",
              "                                 sentence2_segment_text  \n",
              "0     [to him, Referring, Amrozi accused his brother...  \n",
              "2     [the ship 's owners, explosives, On June 10 ,,...  \n",
              "4     [PG & E Corp. shares, jumped, to, on Friday, o...  \n",
              "5     [the first quarter of the year, With the scand...  \n",
              "7     [DVD CCA, U.S., that decision, The appealed to...  \n",
              "...                                                 ...  \n",
              "5792  [Gehring waived extradition Monday during a he...  \n",
              "5793  [the Silver statement, the Silver statement, ,...  \n",
              "5795  [acquisition, close, The acquisition has been ...  \n",
              "5799  [Corp., Drax, American, owner, last week, The ...  \n",
              "5800  [The virus, like, and, familiar, spreads when ...  \n",
              "\n",
              "[3900 rows x 13 columns]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "positives = etpc.loc[etpc['mrpc_label'] == 1]\n",
        "positives.rename(columns={'sentence1_segment_location': 'sentence1_scope_etpc', \n",
        "                          'sentence2_segment_location': 'sentence2_scope_etpc'}, inplace=True)\n",
        "positives.drop(columns=['sentence1_segment_location_indices', 'sentence2_segment_location_indices'],inplace=True)\n",
        "positives['idx'] = positives.index.to_series()\n",
        "positives"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Why we cannot use the ETPC from Wahle et al."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here's a fundamental part of the ETPC that I hadn't realized until now: each token in a sentence can have *more than one* paraphrase type. Here's an example--note how, in sentence 2, token 5 appears in the scopes both of inflectional and derivational changes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pair_id</th>\n",
              "      <th>type_id</th>\n",
              "      <th>type_name</th>\n",
              "      <th>sense_preserving</th>\n",
              "      <th>s1_scope</th>\n",
              "      <th>s2_scope</th>\n",
              "      <th>s1_text</th>\n",
              "      <th>s2_text</th>\n",
              "      <th>key_s1</th>\n",
              "      <th>key_s2</th>\n",
              "      <th>k1_text</th>\n",
              "      <th>k2_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>15963</th>\n",
              "      <td>4206</td>\n",
              "      <td>1</td>\n",
              "      <td>Inflectional Changes</td>\n",
              "      <td>yes</td>\n",
              "      <td>[3]</td>\n",
              "      <td>[3, 5]</td>\n",
              "      <td>completed</td>\n",
              "      <td>had inspected</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15964</th>\n",
              "      <td>4206</td>\n",
              "      <td>3</td>\n",
              "      <td>Derivational Changes</td>\n",
              "      <td>yes</td>\n",
              "      <td>[4]</td>\n",
              "      <td>[5]</td>\n",
              "      <td>inspections</td>\n",
              "      <td>inspected</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       pair_id  type_id             type_name sense_preserving s1_scope  \\\n",
              "15963     4206        1  Inflectional Changes              yes      [3]   \n",
              "15964     4206        3  Derivational Changes              yes      [4]   \n",
              "\n",
              "      s2_scope      s1_text        s2_text key_s1 key_s2 k1_text k2_text  \n",
              "15963   [3, 5]    completed  had inspected   None   None    None    None  \n",
              "15964      [5]  inspections      inspected   None   None    None    None  "
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ric = textual_paraphrases.loc[(textual_paraphrases['pair_id'] == 4205+1) & (textual_paraphrases['type_id'].isin([3,1]))]\n",
        "ric[:2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It seems that this issue also wasn't noticed by Wahle et al: some paraphrase scopes consist of only a single number repeated for the entirety of the list:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>idx</th>\n",
              "      <th>sentence1</th>\n",
              "      <th>sentence2</th>\n",
              "      <th>sentence1_tokenized</th>\n",
              "      <th>sentence2_tokenized</th>\n",
              "      <th>etpc_label</th>\n",
              "      <th>mrpc_label</th>\n",
              "      <th>ept_names</th>\n",
              "      <th>ept_ids</th>\n",
              "      <th>sentence1_scope_etpc</th>\n",
              "      <th>sentence2_scope_etpc</th>\n",
              "      <th>sentence1_segment_text</th>\n",
              "      <th>sentence2_segment_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>14</td>\n",
              "      <td>He told The Sun newspaper that Mr. Hussein's d...</td>\n",
              "      <td>\"Saddam's daughters had British schools and ho...</td>\n",
              "      <td>[He, told, The, Sun, newspaper, that, Mr., Hus...</td>\n",
              "      <td>[``, Saddam, 's, daughters, had, British, scho...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>[Same Polarity Substitution (named ent.), Same...</td>\n",
              "      <td>[7, 6, 7, 26, 25, 29, 21]</td>\n",
              "      <td>[29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 2...</td>\n",
              "      <td>[0, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26...</td>\n",
              "      <td>[Hussein, The Sun newspaper, Mr. Hussein, Mr. ...</td>\n",
              "      <td>[Saddam, The Sun, Saddam, Saddam 's daughters ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>22</td>\n",
              "      <td>But tropical storm warnings and watches were p...</td>\n",
              "      <td>Tropical storm warnings were in place Thursday...</td>\n",
              "      <td>[But, tropical, storm, warnings, and, watches,...</td>\n",
              "      <td>[Tropical, storm, warnings, were, in, place, T...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>[Addition/Deletion, Addition/Deletion, Identit...</td>\n",
              "      <td>[25, 25, 29, 30, 4, 6, 11, 17]</td>\n",
              "      <td>[11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 1...</td>\n",
              "      <td>[11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 1...</td>\n",
              "      <td>[But, tropical storm warnings watches , the so...</td>\n",
              "      <td>[Jamaica and, storm warnings watches , the sou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>35</td>\n",
              "      <td>Trading in Loral was halted yesterday; the sha...</td>\n",
              "      <td>The New York Stock Exchange suspended trading ...</td>\n",
              "      <td>[Trading, in, Loral, was, halted, yesterday, ;...</td>\n",
              "      <td>[The, New, York, Stock, Exchange, suspended, t...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>[Same Polarity Substitution (habitual), Diathe...</td>\n",
              "      <td>[5, 14, 18, 29, 30, 21]</td>\n",
              "      <td>[21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 2...</td>\n",
              "      <td>[21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 2...</td>\n",
              "      <td>[halted, Trading in Loral was halted, Trading ...</td>\n",
              "      <td>[suspended, The New York Stock Exchange suspen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>40</td>\n",
              "      <td>Last year the court upheld Cleveland's school ...</td>\n",
              "      <td>Last year, the court ruled 5-4 in an Ohio case...</td>\n",
              "      <td>[Last, year, the, court, upheld, Cleveland, 's...</td>\n",
              "      <td>[Last, year, ,, the, court, ruled, 5-4, in, an...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>[Same Polarity Substitution (contextual), Infl...</td>\n",
              "      <td>[6, 1, 25, 25, 29, 28, 21]</td>\n",
              "      <td>[29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 2...</td>\n",
              "      <td>[29, 29, 0, 0, 0, 0, 0, 0, 0, 0, 0, 29, 25, 29...</td>\n",
              "      <td>[provide, choice, Last year that vouchers are ...</td>\n",
              "      <td>[provide with, choices, government, among a ra...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>63</td>\n",
              "      <td>Contrary to what PeopleSoft management would h...</td>\n",
              "      <td>Ellison said that contrary to the contentions ...</td>\n",
              "      <td>[Contrary, to, what, PeopleSoft, management, w...</td>\n",
              "      <td>[Ellison, said, that, contrary, to, the, conte...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>[Addition/Deletion, Identity, Semantic based, ...</td>\n",
              "      <td>[25, 29, 28, 21]</td>\n",
              "      <td>[28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 2...</td>\n",
              "      <td>[25, 25, 0, 29, 29, 28, 28, 28, 28, 28, 29, 29...</td>\n",
              "      <td>[Contrary to , Oracle intends to fully support...</td>\n",
              "      <td>[Ellison said, contrary to , Oracle intends to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>72</td>\n",
              "      <td>Also demonstrating box-office strength _ and g...</td>\n",
              "      <td>Also demonstrating box-office strength -- and ...</td>\n",
              "      <td>[Also, demonstrating, box-office, strength, _,...</td>\n",
              "      <td>[Also, demonstrating, box-office, strength, --...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>[Spelling changes, Spelling changes, Identity,...</td>\n",
              "      <td>[4, 4, 29, 21, 21]</td>\n",
              "      <td>[21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 2...</td>\n",
              "      <td>[21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 2...</td>\n",
              "      <td>[O'Neill 's, Day 's, Also demonstrating box-of...</td>\n",
              "      <td>[ONeills, Days, Also demonstrating box-office ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>86</td>\n",
              "      <td>Sales - a figure watched closely as a baromete...</td>\n",
              "      <td>It also disclosed that sales -- a figure close...</td>\n",
              "      <td>[Sales, -, a, figure, watched, closely, as, a,...</td>\n",
              "      <td>[It, also, disclosed, that, sales, --, a, figu...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>[Same Polarity Substitution (habitual), Synthe...</td>\n",
              "      <td>[5, 11, 26, 25, 25, 25, 25, 29, 28, 21]</td>\n",
              "      <td>[25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 2...</td>\n",
              "      <td>[25, 25, 25, 0, 25, 0, 25, 25, 26, 25, 25, 25,...</td>\n",
              "      <td>[rose, many industry experts, closely, 5 perce...</td>\n",
              "      <td>[were higher, industry experts, closely, by an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111</th>\n",
              "      <td>111</td>\n",
              "      <td>The suite comes complete with a word processor...</td>\n",
              "      <td>The suite includes a word processor, spreadshe...</td>\n",
              "      <td>[The, suite, comes, complete, with, a, word, p...</td>\n",
              "      <td>[The, suite, includes, a, word, processor, ,, ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>[Same Polarity Substitution (habitual), Same P...</td>\n",
              "      <td>[5, 5, 6, 5, 11, 18, 25, 25, 29, 21, 21]</td>\n",
              "      <td>[21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 2...</td>\n",
              "      <td>[21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 2...</td>\n",
              "      <td>[comes complete with, software, utilizing, an,...</td>\n",
              "      <td>[includes, application, built around, the, XML...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>124</th>\n",
              "      <td>124</td>\n",
              "      <td>Powell fired back: \"He's accusing the presiden...</td>\n",
              "      <td>If so, Powell said, he's calling the president...</td>\n",
              "      <td>[Powell, fired, back, :, ``, He, 's, accusing,...</td>\n",
              "      <td>[If, so, ,, Powell, said, ,, he, 's, calling, ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>[Same Polarity Substitution (contextual), Same...</td>\n",
              "      <td>[6, 6, 26, 25, 25, 25, 25, 29, 21]</td>\n",
              "      <td>[25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 2...</td>\n",
              "      <td>[25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 2...</td>\n",
              "      <td>[accusing, he, , he said, Powell fired back :,...</td>\n",
              "      <td>[calling, Powell, , Powell said ,, , too, If s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>126</th>\n",
              "      <td>126</td>\n",
              "      <td>The memo on protecting sales of Windows and ot...</td>\n",
              "      <td>The memo specifically mentioned Linux, a still...</td>\n",
              "      <td>[The, memo, on, protecting, sales, of, Windows...</td>\n",
              "      <td>[The, memo, specifically, mentioned, Linux, ,,...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>[Addition/Deletion, Addition/Deletion, Identity]</td>\n",
              "      <td>[25, 25, 29]</td>\n",
              "      <td>[25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 2...</td>\n",
              "      <td>[25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 2...</td>\n",
              "      <td>[on protecting sales of Windows and other desk...</td>\n",
              "      <td>[specifically, The memo mentioned Linux , a st...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     idx                                          sentence1  \\\n",
              "14    14  He told The Sun newspaper that Mr. Hussein's d...   \n",
              "22    22  But tropical storm warnings and watches were p...   \n",
              "35    35  Trading in Loral was halted yesterday; the sha...   \n",
              "40    40  Last year the court upheld Cleveland's school ...   \n",
              "63    63  Contrary to what PeopleSoft management would h...   \n",
              "72    72  Also demonstrating box-office strength _ and g...   \n",
              "86    86  Sales - a figure watched closely as a baromete...   \n",
              "111  111  The suite comes complete with a word processor...   \n",
              "124  124  Powell fired back: \"He's accusing the presiden...   \n",
              "126  126  The memo on protecting sales of Windows and ot...   \n",
              "\n",
              "                                             sentence2  \\\n",
              "14   \"Saddam's daughters had British schools and ho...   \n",
              "22   Tropical storm warnings were in place Thursday...   \n",
              "35   The New York Stock Exchange suspended trading ...   \n",
              "40   Last year, the court ruled 5-4 in an Ohio case...   \n",
              "63   Ellison said that contrary to the contentions ...   \n",
              "72   Also demonstrating box-office strength -- and ...   \n",
              "86   It also disclosed that sales -- a figure close...   \n",
              "111  The suite includes a word processor, spreadshe...   \n",
              "124  If so, Powell said, he's calling the president...   \n",
              "126  The memo specifically mentioned Linux, a still...   \n",
              "\n",
              "                                   sentence1_tokenized  \\\n",
              "14   [He, told, The, Sun, newspaper, that, Mr., Hus...   \n",
              "22   [But, tropical, storm, warnings, and, watches,...   \n",
              "35   [Trading, in, Loral, was, halted, yesterday, ;...   \n",
              "40   [Last, year, the, court, upheld, Cleveland, 's...   \n",
              "63   [Contrary, to, what, PeopleSoft, management, w...   \n",
              "72   [Also, demonstrating, box-office, strength, _,...   \n",
              "86   [Sales, -, a, figure, watched, closely, as, a,...   \n",
              "111  [The, suite, comes, complete, with, a, word, p...   \n",
              "124  [Powell, fired, back, :, ``, He, 's, accusing,...   \n",
              "126  [The, memo, on, protecting, sales, of, Windows...   \n",
              "\n",
              "                                   sentence2_tokenized  etpc_label  \\\n",
              "14   [``, Saddam, 's, daughters, had, British, scho...           1   \n",
              "22   [Tropical, storm, warnings, were, in, place, T...           0   \n",
              "35   [The, New, York, Stock, Exchange, suspended, t...           0   \n",
              "40   [Last, year, ,, the, court, ruled, 5-4, in, an...           1   \n",
              "63   [Ellison, said, that, contrary, to, the, conte...           1   \n",
              "72   [Also, demonstrating, box-office, strength, --...           1   \n",
              "86   [It, also, disclosed, that, sales, --, a, figu...           1   \n",
              "111  [The, suite, includes, a, word, processor, ,, ...           1   \n",
              "124  [If, so, ,, Powell, said, ,, he, 's, calling, ...           1   \n",
              "126  [The, memo, specifically, mentioned, Linux, ,,...           1   \n",
              "\n",
              "     mrpc_label                                          ept_names  \\\n",
              "14            1  [Same Polarity Substitution (named ent.), Same...   \n",
              "22            1  [Addition/Deletion, Addition/Deletion, Identit...   \n",
              "35            1  [Same Polarity Substitution (habitual), Diathe...   \n",
              "40            1  [Same Polarity Substitution (contextual), Infl...   \n",
              "63            1  [Addition/Deletion, Identity, Semantic based, ...   \n",
              "72            1  [Spelling changes, Spelling changes, Identity,...   \n",
              "86            1  [Same Polarity Substitution (habitual), Synthe...   \n",
              "111           1  [Same Polarity Substitution (habitual), Same P...   \n",
              "124           1  [Same Polarity Substitution (contextual), Same...   \n",
              "126           1   [Addition/Deletion, Addition/Deletion, Identity]   \n",
              "\n",
              "                                      ept_ids  \\\n",
              "14                  [7, 6, 7, 26, 25, 29, 21]   \n",
              "22             [25, 25, 29, 30, 4, 6, 11, 17]   \n",
              "35                    [5, 14, 18, 29, 30, 21]   \n",
              "40                 [6, 1, 25, 25, 29, 28, 21]   \n",
              "63                           [25, 29, 28, 21]   \n",
              "72                         [4, 4, 29, 21, 21]   \n",
              "86    [5, 11, 26, 25, 25, 25, 25, 29, 28, 21]   \n",
              "111  [5, 5, 6, 5, 11, 18, 25, 25, 29, 21, 21]   \n",
              "124        [6, 6, 26, 25, 25, 25, 25, 29, 21]   \n",
              "126                              [25, 25, 29]   \n",
              "\n",
              "                                  sentence1_scope_etpc  \\\n",
              "14   [29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 2...   \n",
              "22   [11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 1...   \n",
              "35   [21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 2...   \n",
              "40   [29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 29, 2...   \n",
              "63   [28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 28, 2...   \n",
              "72   [21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 2...   \n",
              "86   [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 2...   \n",
              "111  [21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 2...   \n",
              "124  [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 2...   \n",
              "126  [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 2...   \n",
              "\n",
              "                                  sentence2_scope_etpc  \\\n",
              "14   [0, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26, 26...   \n",
              "22   [11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 1...   \n",
              "35   [21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 2...   \n",
              "40   [29, 29, 0, 0, 0, 0, 0, 0, 0, 0, 0, 29, 25, 29...   \n",
              "63   [25, 25, 0, 29, 29, 28, 28, 28, 28, 28, 29, 29...   \n",
              "72   [21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 2...   \n",
              "86   [25, 25, 25, 0, 25, 0, 25, 25, 26, 25, 25, 25,...   \n",
              "111  [21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 21, 2...   \n",
              "124  [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 2...   \n",
              "126  [25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 2...   \n",
              "\n",
              "                                sentence1_segment_text  \\\n",
              "14   [Hussein, The Sun newspaper, Mr. Hussein, Mr. ...   \n",
              "22   [But, tropical storm warnings watches , the so...   \n",
              "35   [halted, Trading in Loral was halted, Trading ...   \n",
              "40   [provide, choice, Last year that vouchers are ...   \n",
              "63   [Contrary to , Oracle intends to fully support...   \n",
              "72   [O'Neill 's, Day 's, Also demonstrating box-of...   \n",
              "86   [rose, many industry experts, closely, 5 perce...   \n",
              "111  [comes complete with, software, utilizing, an,...   \n",
              "124  [accusing, he, , he said, Powell fired back :,...   \n",
              "126  [on protecting sales of Windows and other desk...   \n",
              "\n",
              "                                sentence2_segment_text  \n",
              "14   [Saddam, The Sun, Saddam, Saddam 's daughters ...  \n",
              "22   [Jamaica and, storm warnings watches , the sou...  \n",
              "35   [suspended, The New York Stock Exchange suspen...  \n",
              "40   [provide with, choices, government, among a ra...  \n",
              "63   [Ellison said, contrary to , Oracle intends to...  \n",
              "72   [ONeills, Days, Also demonstrating box-office ...  \n",
              "86   [were higher, industry experts, closely, by an...  \n",
              "111  [includes, application, built around, the, XML...  \n",
              "124  [calling, Powell, , Powell said ,, , too, If s...  \n",
              "126  [specifically, The memo mentioned Linux , a st...  "
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "positives[positives['sentence1_scope_etpc'].apply(lambda x: (len(np.unique(x)) == 1))][:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The issue also exists in part in the original ETPC: some paraphrase types have scopes annotated as pretty much the entire sentence. This seems especially prevalent among 'Punctuation changes'.\n",
        "\n",
        "TODO: rewrite this, show examples "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "While this is certainly an issue for the original ETPC, it's at least partly offset there since their annotation scheme has separate scopes for each paraphrase type. So even if the annotated scope of some given type isn't very informative, the entire sentence isn't lost: you'd still have other paraphrase types, which are most likely annotated correctly. But Wahle's dataset (and consequently his training pipeline) doesn't account for this. Whatever process Wahle et al. used for generating that dataset on Huggingface seems to have an especially hard time with sentences in the original ETPC as exemplified above, but the issue happens throughout *all* their dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Getting paraphrases from the original ETPC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's first clean up the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence1</th>\n",
              "      <th>sentence2</th>\n",
              "      <th>sentence1_tokenized</th>\n",
              "      <th>sentence2_tokenized</th>\n",
              "      <th>ept_names</th>\n",
              "      <th>ept_ids</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Amrozi accused his brother, whom he called \"th...</td>\n",
              "      <td>Referring to him as only \"the witness\", Amrozi...</td>\n",
              "      <td>[Amrozi, accused, his, brother, ,, whom, he, c...</td>\n",
              "      <td>[Referring, to, him, as, only, ``, the, witnes...</td>\n",
              "      <td>[Same Polarity Substitution (habitual), Same P...</td>\n",
              "      <td>[5, 6, 26, 25, 29]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>They had published an advertisement on the Int...</td>\n",
              "      <td>On June 10, the ship's owners had published an...</td>\n",
              "      <td>[They, had, published, an, advertisement, on, ...</td>\n",
              "      <td>[On, June, 10, ,, the, ship, 's, owners, had, ...</td>\n",
              "      <td>[Same Polarity Substitution (contextual), Same...</td>\n",
              "      <td>[6, 6, 26, 25, 29]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The stock rose $2.11, or about 11 percent, to ...</td>\n",
              "      <td>PG&amp;E Corp. shares jumped $1.63 or 8 percent to...</td>\n",
              "      <td>[The, stock, rose, $, 2.11, ,, or, about, 11, ...</td>\n",
              "      <td>[PG, &amp;, E, Corp., shares, jumped, $, 1.63, or,...</td>\n",
              "      <td>[Same Polarity Substitution (contextual), Same...</td>\n",
              "      <td>[6, 5, 6, 11, 26, 25, 29, 30, 30, 30, 21]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Revenue in the first quarter of the year dropp...</td>\n",
              "      <td>With the scandal hanging over Stewart's compan...</td>\n",
              "      <td>[Revenue, in, the, first, quarter, of, the, ye...</td>\n",
              "      <td>[With, the, scandal, hanging, over, Stewart, '...</td>\n",
              "      <td>[Synthetic/analytic substitution, Addition/Del...</td>\n",
              "      <td>[11, 25, 29]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>The DVD-CCA then appealed to the state Supreme...</td>\n",
              "      <td>The DVD CCA appealed that decision to the U.S....</td>\n",
              "      <td>[The, DVD-CCA, then, appealed, to, the, state,...</td>\n",
              "      <td>[The, DVD, CCA, appealed, that, decision, to, ...</td>\n",
              "      <td>[Spelling changes, Same Polarity Substitution ...</td>\n",
              "      <td>[4, 5, 25, 25, 29]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5792</th>\n",
              "      <td>Gehring waived extradition Monday during a hea...</td>\n",
              "      <td>Gehring waived extradition Monday during a hea...</td>\n",
              "      <td>[Gehring, waived, extradition, Monday, during,...</td>\n",
              "      <td>[Gehring, waived, extradition, Monday, during,...</td>\n",
              "      <td>[Addition/Deletion, Identity, Punctuation chan...</td>\n",
              "      <td>[25, 29, 21, 6, 11, 14, 26, 25]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5793</th>\n",
              "      <td>\"I am advised that certain allegations of crim...</td>\n",
              "      <td>\"I am advised that certain allegations of crim...</td>\n",
              "      <td>[``, I, am, advised, that, certain, allegation...</td>\n",
              "      <td>[``, I, am, advised, that, certain, allegation...</td>\n",
              "      <td>[Same Polarity Substitution (contextual), Chan...</td>\n",
              "      <td>[6, 26, 25, 29, 21]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5795</th>\n",
              "      <td>The deal, approved by both companies' board of...</td>\n",
              "      <td>The acquisition has been approved by both comp...</td>\n",
              "      <td>[The, deal, ,, approved, by, both, companies, ...</td>\n",
              "      <td>[The, acquisition, has, been, approved, by, bo...</td>\n",
              "      <td>[Same Polarity Substitution (habitual), Same P...</td>\n",
              "      <td>[5, 5, 18, 29, 30]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5799</th>\n",
              "      <td>Last week the power station’s US owners, AES C...</td>\n",
              "      <td>The news comes after Drax's American owner, AE...</td>\n",
              "      <td>[Last, week, the, power, station’s, US, owners...</td>\n",
              "      <td>[The, news, comes, after, Drax, 's, American, ...</td>\n",
              "      <td>[Spelling changes, Same Polarity Substitution ...</td>\n",
              "      <td>[4, 7, 6, 1, 26, 25, 25, 25, 29]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5800</th>\n",
              "      <td>Sobig.F spreads when unsuspecting computer use...</td>\n",
              "      <td>The virus spreads when unsuspecting computer u...</td>\n",
              "      <td>[Sobig.F, spreads, when, unsuspecting, compute...</td>\n",
              "      <td>[The, virus, spreads, when, unsuspecting, comp...</td>\n",
              "      <td>[Same Polarity Substitution (named ent.), Same...</td>\n",
              "      <td>[7, 6, 6, 11, 25, 29]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3900 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              sentence1  \\\n",
              "0     Amrozi accused his brother, whom he called \"th...   \n",
              "2     They had published an advertisement on the Int...   \n",
              "4     The stock rose $2.11, or about 11 percent, to ...   \n",
              "5     Revenue in the first quarter of the year dropp...   \n",
              "7     The DVD-CCA then appealed to the state Supreme...   \n",
              "...                                                 ...   \n",
              "5792  Gehring waived extradition Monday during a hea...   \n",
              "5793  \"I am advised that certain allegations of crim...   \n",
              "5795  The deal, approved by both companies' board of...   \n",
              "5799  Last week the power station’s US owners, AES C...   \n",
              "5800  Sobig.F spreads when unsuspecting computer use...   \n",
              "\n",
              "                                              sentence2  \\\n",
              "0     Referring to him as only \"the witness\", Amrozi...   \n",
              "2     On June 10, the ship's owners had published an...   \n",
              "4     PG&E Corp. shares jumped $1.63 or 8 percent to...   \n",
              "5     With the scandal hanging over Stewart's compan...   \n",
              "7     The DVD CCA appealed that decision to the U.S....   \n",
              "...                                                 ...   \n",
              "5792  Gehring waived extradition Monday during a hea...   \n",
              "5793  \"I am advised that certain allegations of crim...   \n",
              "5795  The acquisition has been approved by both comp...   \n",
              "5799  The news comes after Drax's American owner, AE...   \n",
              "5800  The virus spreads when unsuspecting computer u...   \n",
              "\n",
              "                                    sentence1_tokenized  \\\n",
              "0     [Amrozi, accused, his, brother, ,, whom, he, c...   \n",
              "2     [They, had, published, an, advertisement, on, ...   \n",
              "4     [The, stock, rose, $, 2.11, ,, or, about, 11, ...   \n",
              "5     [Revenue, in, the, first, quarter, of, the, ye...   \n",
              "7     [The, DVD-CCA, then, appealed, to, the, state,...   \n",
              "...                                                 ...   \n",
              "5792  [Gehring, waived, extradition, Monday, during,...   \n",
              "5793  [``, I, am, advised, that, certain, allegation...   \n",
              "5795  [The, deal, ,, approved, by, both, companies, ...   \n",
              "5799  [Last, week, the, power, station’s, US, owners...   \n",
              "5800  [Sobig.F, spreads, when, unsuspecting, compute...   \n",
              "\n",
              "                                    sentence2_tokenized  \\\n",
              "0     [Referring, to, him, as, only, ``, the, witnes...   \n",
              "2     [On, June, 10, ,, the, ship, 's, owners, had, ...   \n",
              "4     [PG, &, E, Corp., shares, jumped, $, 1.63, or,...   \n",
              "5     [With, the, scandal, hanging, over, Stewart, '...   \n",
              "7     [The, DVD, CCA, appealed, that, decision, to, ...   \n",
              "...                                                 ...   \n",
              "5792  [Gehring, waived, extradition, Monday, during,...   \n",
              "5793  [``, I, am, advised, that, certain, allegation...   \n",
              "5795  [The, acquisition, has, been, approved, by, bo...   \n",
              "5799  [The, news, comes, after, Drax, 's, American, ...   \n",
              "5800  [The, virus, spreads, when, unsuspecting, comp...   \n",
              "\n",
              "                                              ept_names  \\\n",
              "0     [Same Polarity Substitution (habitual), Same P...   \n",
              "2     [Same Polarity Substitution (contextual), Same...   \n",
              "4     [Same Polarity Substitution (contextual), Same...   \n",
              "5     [Synthetic/analytic substitution, Addition/Del...   \n",
              "7     [Spelling changes, Same Polarity Substitution ...   \n",
              "...                                                 ...   \n",
              "5792  [Addition/Deletion, Identity, Punctuation chan...   \n",
              "5793  [Same Polarity Substitution (contextual), Chan...   \n",
              "5795  [Same Polarity Substitution (habitual), Same P...   \n",
              "5799  [Spelling changes, Same Polarity Substitution ...   \n",
              "5800  [Same Polarity Substitution (named ent.), Same...   \n",
              "\n",
              "                                        ept_ids  \n",
              "0                            [5, 6, 26, 25, 29]  \n",
              "2                            [6, 6, 26, 25, 29]  \n",
              "4     [6, 5, 6, 11, 26, 25, 29, 30, 30, 30, 21]  \n",
              "5                                  [11, 25, 29]  \n",
              "7                            [4, 5, 25, 25, 29]  \n",
              "...                                         ...  \n",
              "5792            [25, 29, 21, 6, 11, 14, 26, 25]  \n",
              "5793                        [6, 26, 25, 29, 21]  \n",
              "5795                         [5, 5, 18, 29, 30]  \n",
              "5799           [4, 7, 6, 1, 26, 25, 25, 25, 29]  \n",
              "5800                      [7, 6, 6, 11, 25, 29]  \n",
              "\n",
              "[3900 rows x 6 columns]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "positives.drop(columns=['idx', 'etpc_label', 'mrpc_label', \n",
        "                                       'sentence1_scope_etpc', \n",
        "                                       'sentence2_scope_etpc', \n",
        "                                       'sentence1_segment_text', \n",
        "                                       'sentence2_segment_text'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We'll need a column to house the new scopes. Let's initialize that column with empty arrays for each token in the sentence. That way, we can easily tell which tokens haven't been annotated yet."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_34451/1356746713.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  positives['sentence1_scope'] = positives['sentence1_tokenized'].apply(lambda x: np.array(['' for _ in x]).astype('U64'))\n",
            "/tmp/ipykernel_34451/1356746713.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  positives['sentence2_scope'] = positives['sentence2_tokenized'].apply(lambda x: np.array(['' for _ in x]).astype('U64'))\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array(['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
              "       '', ''], dtype='<U64')"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#TODO: get rid of SettingWithCopyWarning\n",
        "positives['sentence1_scope'] = positives['sentence1_tokenized'].apply(lambda x: np.array(['' for _ in x]).astype('U64'))\n",
        "positives['sentence2_scope'] = positives['sentence2_tokenized'].apply(lambda x: np.array(['' for _ in x]).astype('U64'))\n",
        "positives['sentence1_scope'][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Populating types"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Helper function to populate type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Convert to df apply (rather than series apply on idx)\n",
        "# TODO: Figure out if 64 char limit will be an issue\n",
        "\n",
        "def populate_type(idx, ept_id, lookup_df=textual_paraphrases):\n",
        "    \"\"\"Given a paraphrase pair (idx) and an EPT paraphrase type (ept_id), convert the EPT type to Paraop, look up the \n",
        "    scopes for both sentences in the pair, and fill in the scopes with the Paraop type. Returns a pair of arrays with\n",
        "    the newly annotated scopes.\"\"\"\n",
        "    paraop_id = ept_to_paraop(ept_id)\n",
        "\n",
        "    # Copy array to avoid messing up the originals\n",
        "    array1 = np.copy(positives['sentence1_scope'][idx])\n",
        "    array2 = np.copy(positives['sentence2_scope'][idx])\n",
        "    \n",
        "    # Create a subset of the lookup array containing only the paraphrase types\n",
        "    # we are interested in (ept_id)\n",
        "    subset = lookup_df[(lookup_df['pair_id'] == idx+1) & (lookup_df['type_id'] == int(ept_id))]\n",
        "    subset.reset_index(drop=True, inplace=True)\n",
        "    instances = len(subset['type_id'].values) # Count how many discrete instances of that type are there in this pair\n",
        "\n",
        "    def fill(sentence_n, instance, array, scope):\n",
        "        \"\"\"Helper function for filling in ids\"\"\"\n",
        "        # Identify which indices in the array have not been filled yet\n",
        "        empty = np.where(array == '')[0]\n",
        "        nonempty = np.where(array != '')[0]\n",
        "\n",
        "        # Fill in empty entries\n",
        "        if len(scope) > 0:\n",
        "            empty_intersect = np.intersect1d(scope, empty)\n",
        "            array[empty_intersect] = f'{paraop_id}_{instance}'\n",
        "            \n",
        "        # Append to non-empty entries\n",
        "        nonempty_intersect = np.intersect1d(scope, nonempty)\n",
        "        if len(nonempty_intersect) > 0:\n",
        "            # TODO: Log this in a better way (save to a file instead of just printing)\n",
        "            print(f'Double check type overwriting: row {idx}, sentence {sentence_n}')\n",
        "            print(f'Common indices: {list(nonempty_intersect)}')\n",
        "            array[nonempty_intersect] = np.char.add(array[nonempty_intersect], f' & {paraop_id}_{instance}')\n",
        "\n",
        "    # Filling in\n",
        "    for i in range(instances):\n",
        "        # Get scopes from lookup df\n",
        "        s1_scope = np.array(subset.loc[subset['type_id'] == ept_id, 's1_scope'].iloc[i])\n",
        "        s2_scope = np.array(subset.loc[subset['type_id'] == ept_id, 's2_scope'].iloc[i])\n",
        "        \n",
        "        fill(1, i, array1, s1_scope)\n",
        "        fill(2, i, array2, s2_scope)\n",
        "    \n",
        "    return array1, array2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here's a demo of how the outputs to that function look like:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array(['3_0', '3_0', '3_0', '3_0', '', '', '', '', '', '', '', '', '', '',\n",
              "        '', '', '', '', ''], dtype='<U64'),\n",
              " array(['', '', '', '', '', '', '', '', '', '', '3_0', '3_0', '3_0', '3_0',\n",
              "        '', '', '', '', '', ''], dtype='<U64'))"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "populate_type(0, 26)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([0, 1, 2, 3]),)"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "testie = populate_type(0, 26)[0]\n",
        "#testie\n",
        "mask = testie == '3_0'\n",
        "np.where(mask)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`populate_type` returns new arrays, it doesn't modify the original df. Use the function below to actually modify the df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "def substitute(ept_id, lookup_df=textual_paraphrases):\n",
        "    series = positives['idx'].apply(populate_type, ept_id=ept_id, lookup_df=lookup_df)\n",
        "    cols = pd.DataFrame(series.tolist(), columns=['sentence1', 'sentence2'])\n",
        "    positives.loc[:, 'sentence1_scope'] = cols['sentence1'].values\n",
        "    positives.loc[:, 'sentence2_scope'] = cols['sentence2'].values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Performing the reannotation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Change of order"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Double check type overwriting: row 196, sentence 1\n",
            "Common indices: [2]\n",
            "Double check type overwriting: row 196, sentence 2\n",
            "Common indices: [9]\n",
            "Double check type overwriting: row 411, sentence 1\n",
            "Common indices: [0, 1, 2, 3, 4]\n",
            "Double check type overwriting: row 411, sentence 2\n",
            "Common indices: [12, 13, 14, 15]\n",
            "Double check type overwriting: row 1014, sentence 1\n",
            "Common indices: [5]\n",
            "Double check type overwriting: row 1014, sentence 2\n",
            "Common indices: [10, 11]\n",
            "Double check type overwriting: row 1543, sentence 1\n",
            "Common indices: [19]\n",
            "Double check type overwriting: row 1543, sentence 2\n",
            "Common indices: [5]\n",
            "Double check type overwriting: row 1864, sentence 1\n",
            "Common indices: [5, 6]\n",
            "Double check type overwriting: row 1864, sentence 2\n",
            "Common indices: [11, 12]\n",
            "Double check type overwriting: row 2309, sentence 1\n",
            "Common indices: [0, 1, 2, 3, 4, 5]\n",
            "Double check type overwriting: row 2309, sentence 2\n",
            "Common indices: [10, 11, 12, 13, 14]\n",
            "Double check type overwriting: row 2336, sentence 1\n",
            "Common indices: [12]\n",
            "Double check type overwriting: row 2336, sentence 2\n",
            "Common indices: [5]\n",
            "Double check type overwriting: row 2920, sentence 1\n",
            "Common indices: [25, 26]\n",
            "Double check type overwriting: row 2920, sentence 2\n",
            "Common indices: [5, 6]\n",
            "Double check type overwriting: row 3164, sentence 1\n",
            "Common indices: [6]\n",
            "Double check type overwriting: row 3164, sentence 2\n",
            "Common indices: [19]\n",
            "Double check type overwriting: row 4346, sentence 1\n",
            "Common indices: [13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26]\n",
            "Double check type overwriting: row 4346, sentence 2\n",
            "Common indices: [0, 1, 2, 3, 4, 5, 6, 7, 8]\n",
            "Double check type overwriting: row 4346, sentence 1\n",
            "Common indices: [11]\n",
            "Double check type overwriting: row 4346, sentence 2\n",
            "Common indices: [18]\n",
            "Double check type overwriting: row 4514, sentence 1\n",
            "Common indices: [12, 13, 14, 15]\n",
            "Double check type overwriting: row 4514, sentence 2\n",
            "Common indices: [3, 4, 5, 6, 7]\n"
          ]
        }
      ],
      "source": [
        "substitute(26)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['3_1', '3_1', '3_0 & 3_1', '3_1', '3_1', '3_1', '3_1', '3_1',\n",
              "       '3_1', '3_1', '3_1', '3_1', '', '', ''], dtype='<U64')"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "positives.loc[positives['idx'] == 196, 'sentence1_scope'].iloc[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pair_id</th>\n",
              "      <th>type_id</th>\n",
              "      <th>type_name</th>\n",
              "      <th>sense_preserving</th>\n",
              "      <th>s1_scope</th>\n",
              "      <th>s2_scope</th>\n",
              "      <th>s1_text</th>\n",
              "      <th>s2_text</th>\n",
              "      <th>key_s1</th>\n",
              "      <th>key_s2</th>\n",
              "      <th>k1_text</th>\n",
              "      <th>k2_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>741</th>\n",
              "      <td>197</td>\n",
              "      <td>26</td>\n",
              "      <td>Change of order</td>\n",
              "      <td>yes</td>\n",
              "      <td>[2]</td>\n",
              "      <td>[9]</td>\n",
              "      <td>just</td>\n",
              "      <td>just</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>742</th>\n",
              "      <td>197</td>\n",
              "      <td>26</td>\n",
              "      <td>Change of order</td>\n",
              "      <td>yes</td>\n",
              "      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]</td>\n",
              "      <td>[2, 3, 4, 5, 8, 9, 10, 11, 12, 13, 15]</td>\n",
              "      <td>`` I just got carried away and started making ...</td>\n",
              "      <td>he got carried away and just `` started making...</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     pair_id  type_id        type_name sense_preserving  \\\n",
              "741      197       26  Change of order              yes   \n",
              "742      197       26  Change of order              yes   \n",
              "\n",
              "                                   s1_scope  \\\n",
              "741                                     [2]   \n",
              "742  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]   \n",
              "\n",
              "                                   s2_scope  \\\n",
              "741                                     [9]   \n",
              "742  [2, 3, 4, 5, 8, 9, 10, 11, 12, 13, 15]   \n",
              "\n",
              "                                               s1_text  \\\n",
              "741                                               just   \n",
              "742  `` I just got carried away and started making ...   \n",
              "\n",
              "                                               s2_text key_s1 key_s2 k1_text  \\\n",
              "741                                               just   None   None    None   \n",
              "742  he got carried away and just `` started making...   None   None    None   \n",
              "\n",
              "    k2_text  \n",
              "741    None  \n",
              "742    None  "
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "subset = textual_paraphrases[(textual_paraphrases['pair_id'] == 196+1) & (textual_paraphrases['type_id'] == int(26))]\n",
        "subset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Same Polarity Substitution (Habitual)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "substitute(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Same Polarity Substitution (Contextual)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "substitute(6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Derivational Changes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "substitute(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Inflectional Changes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "substitute(1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Spelling Changes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "substitute(4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Change of format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "substitute(8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Opposite Polarity Substitution (Habitual)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "substitute(9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Modal Verb Changes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Check overlapped words between (e.g.) derivational & inflectional changes\n",
        "# The way this works right now, you'd have something like ['6_0 & 6_0'] for those\n",
        "# Make sure this doesn't happen. Probably do a function that does a pass on the\n",
        "# array of strings later and removes any duplicates"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def trim_duplicates(s1_scope, s2_scope, s1_text, s2_text):\n",
        "    s1_newtext = s1_text.split()\n",
        "    s2_newtext = s2_text.split()\n",
        "    \n",
        "    in1 = np.where(np.in1d(s1_newtext, s2_newtext))[0]\n",
        "    in2 = np.where(np.in1d(s2_newtext, s1_newtext))[0]\n",
        "\n",
        "    s1_newscope = np.delete(s1_scope, in1)\n",
        "    s2_newscope = np.delete(s2_scope, in2)\n",
        "    s1_newtext = ' '.join(np.delete(s1_newtext, in1))\n",
        "    s2_newtext = ' '.join(np.delete(s2_newtext, in2))\n",
        "\n",
        "    return s1_newscope, s2_newscope, s1_newtext, s2_newtext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ric = textual_paraphrases.loc[textual_paraphrases['type_id'].isin([2])]\n",
        "ric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trimmed = pd.DataFrame(columns = ric.columns, data = copy.deepcopy(ric.values))\n",
        "trimmed[['s1_scope', 's2_scope', 's1_text', 's2_text']] = trimmed.apply(lambda x: trim_duplicates(x.s1_scope, x.s2_scope, x.s1_text, x.s2_text), axis=1, result_type='expand')\n",
        "#output = pd.DataFrame(series.tolist(), columns=['s1_scope', 's2_scope', 's1_text', 's2_text'])\n",
        "#output[:30]\n",
        "trimmed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "substitute(2, trimmed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Diagnosing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run these cells to make sure everything looks OK after reannotating"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "positives.loc[positives['idx'] == 2953, 'sentence2_scope'].iloc[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "subset = textual_paraphrases[(textual_paraphrases['pair_id'] == 449+1) & (textual_paraphrases['type_id'] == int(5))]\n",
        "subset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# For diagnosing\n",
        "textual_paraphrases.loc[(textual_paraphrases['pair_id'] == 449+1) & (textual_paraphrases['type_id'].isin([1,5,3,26]))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#TODO: Modal verb needs trimming.\n",
        "#TODO: So does some other one that I forget rn\n",
        "#TODO: Numbers on named entity substitution\n",
        "#TODO: Figure out what's the matter with punctuation changes -- it's the key! Maybe I can use those as indices..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "textual_paraphrases[(textual_paraphrases['type_id'] == 21)][:50]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "positives['sentence1_scope'][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Flagged rows:\n",
        "\n",
        "2432, 5074, 12186\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Sentence modality changes have zero ocurrences among paraphrases"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# The garbage pail"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "auxiliaries = ['are', 'am', 'be', 'been', 'being', 'had', 'has', 'have', 'having', 'is', 'was', 'were']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Code that may or may not be useful will remain here for a while"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Change of Order > Identity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Game plan:\n",
        "\n",
        "Same Polarity Substitution > Derivational Changes > Inflectional Changes > ...Modal Verb Changes? > Change of Order (modified)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Filtering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Helper methods for filtering the ETPC dataframe based on paraphrase types"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def filter_contains(df, search_ids):\n",
        "  \"\"\"Returns an ETPC dataframe with rows where paraphrase_types_ids contains\n",
        "  the search_ids. Use this to search for paraphrase pairs containing specific\n",
        "  ids\"\"\"\n",
        "  return df[df['ept_ids'].apply(lambda x: np.isin(search_ids, x))]\n",
        "\n",
        "def filter_equals(df, search_ids):\n",
        "  \"\"\"Returns an ETPC dataframe with rows where paraphrase_types_ids EXACTLY \n",
        "  MATCHES the search_ids.\"\"\"\n",
        "  return df[df['ept_ids'].apply(lambda x: np.array_equal(x, search_ids))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "filter_contains(etpc, '3')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "filter_equals(etpc, ['25', '29'])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
