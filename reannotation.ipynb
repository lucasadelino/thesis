{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psSg2pvghrou"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "uDeCR0k4i75z"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Reading the ETPC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This is the ETPC dataset compiled by Wahle and posted on HuggingFace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "9Zb32aXAjlKl"
      },
      "outputs": [],
      "source": [
        "# Unpickle etpc_raw\n",
        "etpc = pd.read_pickle('datasets/etpc_raw.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "These are the XML files from the ETPC github repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "textual_paraphrases = pd.read_xml('datasets/etpc/textual_paraphrases.xml')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pairs = pd.read_xml('datasets/etpc/text_pairs.xml')\n",
        "pairs.drop(columns=['negation'], inplace=True)\n",
        "pairs.set_index('pair_id', inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7fEbR8ahnyT"
      },
      "source": [
        "# Cleanup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Cleaning up Columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "etpc.rename(columns={'paraphrase_type_ids': 'ept_ids', 'paraphrase_types': 'ept_names'}, inplace=True)\n",
        "etpc.drop(columns={'negation'}, axis=1, inplace=True)\n",
        "etpc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4V4ebL-5iVhu"
      },
      "source": [
        "## Remapping Paraphrase IDs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1r_HM5DuiwbU"
      },
      "source": [
        "First, make a list with paraphrase types and IDs from the ETPC:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 896
        },
        "id": "g-NHZrIEj_uW",
        "outputId": "c9d1ecfb-59ed-4a96-fd6f-0fc6be15090e"
      },
      "outputs": [],
      "source": [
        "id_map = pd.read_xml('https://raw.githubusercontent.com/venelink/ETPC/master/Corpus/paraphrase_types.xml')\n",
        "# Rename columns for clarity\n",
        "id_map.rename(columns={'type_id': 'ept_id', 'type_name': 'ept_name'}, inplace=True)\n",
        "# Drop unused data\n",
        "id_map = id_map[['ept_id', 'ept_name']] # No use for type_category column\n",
        "id_map.drop(id_map.tail(2).index,inplace=True) # Types don't appear in ETPC\n",
        "id_map.style.hide(axis=\"index\")\n",
        "id_map"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igg_sqcRliXX"
      },
      "source": [
        "Now, make a list with paraphrase names and IDs for ParaOp types"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "ONILD3V0lucp",
        "outputId": "38f25e64-a353-47bb-81b3-fbfa8c09302a"
      },
      "outputs": [],
      "source": [
        "data = [[0, 'No change'],\n",
        "        [1, 'Addition/Deletion - Function Word'],\n",
        "        [2, 'Addition/Deletion - Content Word'],\n",
        "        [3, 'Change of Order'],\n",
        "        [4, 'Substitution - Synonym'],\n",
        "        [5, 'Substitution - Contextual Synonym'],\n",
        "        [6, 'Substitution - Morphological'],\n",
        "        [7, 'Substitution - Spelling and Format']\n",
        "       ]\n",
        "paraop_map = pd.DataFrame(data, columns = ['paraop_id', 'paraop_name'])\n",
        "paraop_map.set_index('paraop_id', inplace=True)\n",
        "paraop_map"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Mapping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We'll use the dataframe below for mapping. Each row will contain the name and ID of a paraphrase type in the ETPC, and the name and ID of the correspondent ParaOp type."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 896
        },
        "id": "_jwKfRbRizo0",
        "outputId": "b0a0994c-22c8-4197-907d-f10095b5d1e4"
      },
      "outputs": [],
      "source": [
        "id_map['paraop_id'] = ''\n",
        "id_map['paraop_name'] = ''\n",
        "id_map"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUz653FebizJ"
      },
      "source": [
        "Here's where we do the mapping:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NKrHh2trtJhn"
      },
      "outputs": [],
      "source": [
        "# Helper function to map an ETPC id to a Paraop id\n",
        "def map_id(ept_id, paraop_id):\n",
        "    \"\"\"Given an EPT id and a Paraop id, look up the name of the Paraop id and \n",
        "    fill in the rows of id_map with paraop_id and the name.\"\"\"\n",
        "    id_map.loc[id_map['ept_id'] == ept_id, 'paraop_id'] = paraop_id\n",
        "    id_map.loc[id_map['ept_id'] == ept_id, 'paraop_name'] = paraop_map.loc[paraop_id, 'paraop_name']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 896
        },
        "id": "cbJDHI9LvQ0e",
        "outputId": "dfc86b17-2cdd-47b4-9285-3dbf06772ad2"
      },
      "outputs": [],
      "source": [
        "map_id(ept_id=1, paraop_id=6)\n",
        "map_id(ept_id=3, paraop_id=6)\n",
        "map_id(ept_id=26, paraop_id=3)\n",
        "map_id(ept_id=29, paraop_id=0)\n",
        "id_map"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXh7ydJQznCV"
      },
      "source": [
        "TODO: Figure out a way to hide index of map_id throughout whole notebook. For some reason this seems harder than it needs to be..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reannotating types"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Helper function to get a Paraop id from an ETPC id\n",
        "def ept_to_paraop(ept_id):\n",
        "    return id_map.loc[id_map['ept_id'] == ept_id, 'paraop_id'].iloc[0]\n",
        "\n",
        "ept_to_paraop(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def substitute_id(id_array, old):\n",
        "    \"\"\"Substitute the ETPC ids in id_array for their corresponding Paraop ids\"\"\"\n",
        "    new = str(ept_to_paraop(old))\n",
        "    copy = id_array.astype('U10') # To allow for more than 4 characters\n",
        "    for i in range(len(copy)):\n",
        "        iid, count = copy[i].split('_')\n",
        "        if iid == str(old):\n",
        "            # Any reannotated types will have a 10 appended to them. This is to\n",
        "            # identify which types have already been reannotated, to avoid \n",
        "            # accidentally reannotating ids that have already been substituted. \n",
        "            copy[i] = f'10{new}_{count}'\n",
        "    return copy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Filtering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Helper methods for filtering the ETPC dataframe based on paraphrase types"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def filter_contains(df, search_ids):\n",
        "  \"\"\"Returns an ETPC dataframe with rows where paraphrase_types_ids contains\n",
        "  the search_ids. Use this to search for paraphrase pairs containing specific\n",
        "  ids\"\"\"\n",
        "  return df[df['ept_ids'].apply(lambda x: np.isin(search_ids, x))]\n",
        "\n",
        "def filter_equals(df, search_ids):\n",
        "  \"\"\"Returns an ETPC dataframe with rows where paraphrase_types_ids EXACTLY \n",
        "  MATCHES the search_ids.\"\"\"\n",
        "  return df[df['ept_ids'].apply(lambda x: np.array_equal(x, search_ids))]W"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "filter_contains(etpc, '3')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "filter_equals(etpc, ['25', '29'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Reannotation, Continued"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Creating Positives"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "positives = etpc.loc[etpc['mrpc_label'] == 1]\n",
        "positives.rename(columns={'sentence1_segment_location': 'sentence1_scope_etpc', 'sentence2_segment_location': 'sentence2_scope_etpc'}, inplace=True)\n",
        "positives.drop(columns=['sentence1_segment_location_indices', 'sentence2_segment_location_indices'],inplace=True)\n",
        "positives['idx'] = positives.index.to_series()\n",
        "positives"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "id_map = id_map.style.hide(axis=\"index\")\n",
        "id_map"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test = filter_contains(positives, '4')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Diagnosing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def diagnose(row, typee):\n",
        "    print('Sentences:')\n",
        "    print(test['sentence1'][row])\n",
        "    print(test['sentence2'][row])\n",
        "    #print(test['sentence1_tokenized'][row])\n",
        "    #print(test['sentence2_tokenized'][row])\n",
        "    print()\n",
        "    print(f'Words where type {typee} is found:')\n",
        "    sent1 = test['sentence1_tokenized'][row]\n",
        "    sent2 = test['sentence2_tokenized'][row]\n",
        "    print(sent1[test['sentence1_scope_etpc'][row] == typee])\n",
        "    print(sent2[test['sentence2_scope_etpc'][row] == typee])\n",
        "    print()\n",
        "    print('Scopes:')\n",
        "    print(test['sentence1_scope_etpc'][row])\n",
        "    print(test['sentence2_scope_etpc'][row])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "diagnose(72, 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_words(df, ept_type):\n",
        "    return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check if ETPC \n",
        "positives[positives['sentence1_scope_etpc'].apply(lambda x: (len(np.unique(x)) == 1))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "positives.drop(columns=['idx', 'etpc_label', 'mrpc_label', \n",
        "                                       'sentence1_scope_etpc', \n",
        "                                       'sentence2_scope_etpc', \n",
        "                                       'sentence1_segment_text', \n",
        "                                       'sentence2_segment_text', \n",
        "                                       'sentence1_scope_paraop', \n",
        "                                       'sentence2_scope_paraop'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "positives['sentence1_scope'] = positives['sentence1_tokenized'].apply(lambda x: np.array(['' for token in x]).astype('U10'))\n",
        "positives['sentence2_scope'] = positives['sentence2_tokenized'].apply(lambda x: np.array(['' for token in x]).astype('U10'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "positives"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def populate_identity(idx):\n",
        "    #n = str(n)\n",
        "    array = np.copy(positives['sentence1_scope'][idx])\n",
        "    subset = textual_paraphrases[(textual_paraphrases['pair_id'] == idx+1)]\n",
        "    scope = subset.loc[subset['type_id'] == 29, 's1_scope']\n",
        "    if len(scope) > 0:\n",
        "        array[scope.iloc[0]] = '0_0'\n",
        "    #print(idx)\n",
        "    return array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "populate_identity(2, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "positives['idx'] = positives.index\n",
        "positives"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "positives['idx'].apply(populate_identity)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "positives[130:150]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ric = textual_paraphrases[textual_paraphrases['pair_id'] == 7+1]\n",
        "ric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "len(ric.loc[ric['type_id'] == 28, 's1_scope'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ric.query('type_id == 29')['s1_scope']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test = positives['sentence1_scope'][0]\n",
        "test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test[textual_paraphrases['s1_scope'][4]] = '0_0'\n",
        "test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pairs.reset_index(inplace=True)\n",
        "pairs.drop(columns=['sent1_indices', 'sent2_indices'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "textual_paraphrases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "textual_paraphrases['s1_scope'][4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def disambiguate_duplicate(idx, lookup_df):\n",
        "    \"\"\"\"Disambiguates duplicate paraphrase types for a row (given its idx) of\n",
        "    the ETPC dataframe. Returns a tuple containing the disambiguated scopes for\n",
        "    each sentence in the pair.\"\"\"\n",
        "    # First, determine what are the duplicates\n",
        "    dups = get_duplicates(etpc['ept_ids'][idx])\n",
        "    # Convert array values to strings with '_0' appended to them\n",
        "    s1_str = np.array([x + '_0' for x in etpc['sentence1_segment_location'][idx].astype(str)])\n",
        "    s2_str = np.array([y + '_0' for y in etpc['sentence2_segment_location'][idx].astype(str)])\n",
        "    # Disambiguate\n",
        "    for iid, count in dups.items():\n",
        "        # Subset the lookup df\n",
        "        subset = lookup_df[(lookup_df['pair_id'] == idx+1) & (lookup_df['type_id'] == int(iid))]\n",
        "        subset.reset_index(drop=True, inplace=True)\n",
        "        for i in range(1, count): # Skip adding zeroes since they're already there\n",
        "            if subset['s1_scope'][i] is not None:\n",
        "                s1_str[subset['s1_scope'][i]] = str(iid) + f'_{str(i)}'\n",
        "            if subset['s2_scope'][i] is not None:\n",
        "                s2_str[subset['s2_scope'][i]] = str(iid) + f'_{str(i)}'\n",
        "    return s1_str, s2_str"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
